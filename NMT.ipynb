{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bishoy576/Neuarl-Machine-translation/blob/main/NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6czvz5VKO5M"
      },
      "source": [
        "# Notebook for Programming in Problem 4\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8HI5JqTvU5"
      },
      "source": [
        "## Learning Objectives\n",
        "In this problem, we will use [PyTorch](https://pytorch.org/) to implement a sequence-to-sequence (seq2seq) transformer model to build a nerual machine translation (NMT) system, which translates from French to English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrHyvWvTyGZ"
      },
      "source": [
        "## Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "You can edit code in the other parts of the notebook too, which can be useful for debugging, but be careful to avoid breaking the provided code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYMKJlKNXYe"
      },
      "source": [
        "## Installing Packages\n",
        "\n",
        "Install PyTorch using pip. See [https://pytorch.org/](https://pytorch.org/) if you want to install it on your computer.\n",
        "In addition, we will also be needing [huggingface](https://huggingface.co/)'s `transformers` and `datasets` libraries, and [nltk](https://www.nltk.org/) to compute the BLEU score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dRVuiP_JVdT",
        "outputId": "cbe5820f-9039-4c74-a423-a352d2e62a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.27.0\n",
            "  Downloading transformers-4.27.0-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (2024.2.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.27.0\n",
            "Collecting datasets==2.10.0\n",
            "  Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (14.0.2)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.10.0)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (4.66.4)\n",
            "Collecting xxhash (from datasets==2.10.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.10.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (24.0)\n",
            "Collecting responses<0.19 (from datasets==2.10.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (2024.2.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.10.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.0) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.10.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "# Pytorch is typically already installed in Google Colab (uncomment to install):\n",
        "# !pip install torch==1.8.0\n",
        "# or for GPU support:\n",
        "# !pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers==4.27.0\n",
        "!pip install datasets==2.10.0\n",
        "# NLTK is typically also already installed in Google Colab (uncomment to install):\n",
        "# !pip install nltk==3.8.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw76yPDhOia1"
      },
      "source": [
        "## Download NMT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL42TT6Tb0S7"
      },
      "source": [
        "We first download the data for NMT, which contains pairs of parallel sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmD7lPOXOlm2"
      },
      "outputs": [],
      "source": [
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a4/resources.zip\n",
        "!unzip -qo resources.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5TS8PG0Os0f"
      },
      "source": [
        "## Data preprocessing\n",
        "In this section we will write code to load and tokenize the data for NMT.\n",
        "\n",
        "\n",
        "The parallel data is provided as huggingface datasets, one for each split of `train`, `validation` and `test`. We load it via the `load_from_disk` method and inspect its features. If you'd like to know more about these dataset objects, have a look at [this tutorial](https://huggingface.co/docs/datasets/access)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxi3D2oX1iIK",
        "outputId": "7a5d4414-5c1e-45b5-c1d0-ff387f0fbef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of splits: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text_en', 'text_fr'],\n",
            "        num_rows: 8701\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text_en', 'text_fr'],\n",
            "        num_rows: 485\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text_en', 'text_fr'],\n",
            "        num_rows: 486\n",
            "    })\n",
            "})\n",
            "First training example: {'text_en': 'i m tough .', 'text_fr': 'je suis dure .'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "raw_text_datasets = load_from_disk(\"resources/parallel_en_fr_corpus\")\n",
        "print(\"Summary of splits:\", raw_text_datasets)\n",
        "print(\"First training example:\", raw_text_datasets[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1NmS9j01iIK"
      },
      "source": [
        "You are also provided with two pre-trained tokenizers for the source and target languages respectively, which we can load with the hugginface transfomers library. [This tutorial](https://huggingface.co/docs/transformers/preprocessing#natural-language-processing) provides an introduction to using pre-trained tokenizers and the powerful `AutoTokenizer` class. The tokenizers are based on byte-pair encodings which break words into smaller units. This is aimed at reducing the sparsity of words, as subwords can be shared between different rare words. If you are interested in learning more, see the paper [Neural Machine Translation of Rare Words with Subword Units](https://www.aclweb.org/anthology/P16-1162.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqnyk7Xo1iIK",
        "outputId": "056789e5-4777-456c-b98c-9bc3f4b77a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of source language: 3200\n",
            "Vocab size of target language: 3200\n",
            "\n",
            "*** Example ***\n",
            "Example sentence: we have an example\n",
            "Tokenizer output: {'input_ids': [1, 64, 324, 103, 266, 1490, 92, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Tokens: ['<s>', '▁we', '▁have', '▁an', '▁ex', 'amp', 'le', '</s>']\n",
            "Reconstructed sentence <s> we have an example</s>\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "source_tokenizer = AutoTokenizer.from_pretrained(\"resources/tokenizer_fr\")\n",
        "target_tokenizer = AutoTokenizer.from_pretrained(\"resources/tokenizer_en\")\n",
        "\n",
        "print(\"Vocab size of source language:\", source_tokenizer.vocab_size)\n",
        "print(\"Vocab size of target language:\", target_tokenizer.vocab_size)\n",
        "\n",
        "# As a demonstration, we will the following English sentence to tokens.\n",
        "example_sentence = \"we have an example\"\n",
        "tokenizer_output = target_tokenizer(example_sentence)\n",
        "print(\"\\n*** Example ***\")\n",
        "print(\"Example sentence:\", example_sentence)\n",
        "print(\"Tokenizer output:\", tokenizer_output)\n",
        "\n",
        "# We convert every token id to its associated string, but find the special character ▁ which indicates the beginning of a word.\n",
        "# Note that very common words are represented by a single token, while others are split into subunits due to the small vocab size.\n",
        "# Also note that †he tokenizer already adds special tokens to the beginning and end of the sentence.\n",
        "decoded_sequence = [target_tokenizer.decode(token) for token in tokenizer_output[\"input_ids\"]]\n",
        "print(\"Tokens:\", decoded_sequence)\n",
        "\n",
        "# By replacing the special character ▁ with whitespace, we can reconstruct a legibile sentence,\n",
        "# which differs from the original example by special tokens, includings <unk> tokens, and minor whitespace differences.\n",
        "reconstructed = \"\".join(decoded_sequence).replace(\"▁\", \" \")\n",
        "print(\"Reconstructed sentence\", reconstructed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ui6m-oh1iIL"
      },
      "source": [
        "We now want to convert the entire dataset to token ids.\n",
        "Specifically, we want to use the tokenizers to create a dataset with\n",
        "features \"encoder_input_ids\" and \"decoder_input_ids\", which both have type `List[int]`\n",
        "and which will later be the inputs to our encoder-decoder model. We will implement this using the powerful `map` function. You can find its API reference [here](https://huggingface.co/docs/datasets/v2.10.0/en/package_reference/main_classes#datasets.Dataset.map)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419,
          "referenced_widgets": [
            "5ae846721324468eb29cf8e5154ef661",
            "3a1a4551f0f94a01bcfce63a61d70152",
            "cec3fe713de34cf08f3f02bc784fccc3",
            "20237bfdb8b44f308c3a36b9e694dd52",
            "e067e961c0f44b5aa34cd7708080bbf5",
            "755a7f249f2c48bf9c1a2d0606f7ce01",
            "1da76628f79e4805bf6f4a4c95322510",
            "7eefe37f41484e9ab2930485fe142601",
            "66926707f2534cb98a9f1203d82cf00b",
            "4e77654103dc4fe9b9a12a8ea16e166e",
            "70f8f8f39dff496589367bb5ce6c5a35",
            "0222d46c7b7542e2b0864b99bfbde062",
            "5f0e96193db94721aa1e628826877dbf",
            "ee8559723f6a451196fc49f9780eb7a8",
            "bd3da4b876724cc6b38a61e5074cedc0",
            "81a093b65ac14ce098b064fa31b76aa9",
            "de2b4dbf424c4ba9b3073a2d2be907a0",
            "40162021b70b45aa864078ff49d2d0bb",
            "d7249d0ad79143cfa37040e3cc4fec55",
            "75737cd71c2644a982f8dcc53228a9c4",
            "97bf8967c3c74113a2a83dd350e7860b",
            "eb647d942b04475e97c9bd80b0d11ff3",
            "e96ce9e1257e4e00943b2f8a207c729c",
            "465bc1cd7f944410aea3bc39206dd00a",
            "f91b3fdc63d949609448f6b7e596a061",
            "49229dff63fd4f19820a6e4bc85e75ba",
            "f1a607275fc44d0095cbca082132a9a9",
            "60e5132579e0483a9c480b24794ceea5",
            "b1845194a1ad4ff28053ab5b7adea400",
            "b8fa8069369d41b8932d9d9a92541041",
            "023b8a95d97b45e2be78d8330671d2fc",
            "3aca2d9b84764f2c9fd1a46531ee8d69",
            "9af3b1377f9442608a493e30b25b8162"
          ]
        },
        "id": "XPb6HpAH1iIL",
        "outputId": "2968cec6-839c-4341-9e3e-394ecaa42d2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8701 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ae846721324468eb29cf8e5154ef661"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/485 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0222d46c7b7542e2b0864b99bfbde062"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/486 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e96ce9e1257e4e00943b2f8a207c729c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 0:\n",
            "Encoder input IDs: [1, 47, 60, 1449, 36, 2]\n",
            "Decoder input IDs: [1, 37, 42, 1044, 35, 2]\n",
            "Source text (decoded): ▁je ▁suis ▁dure ▁.\n",
            "Target text (decoded): ▁i ▁m ▁tough ▁.\n",
            "\n",
            "Example 1:\n",
            "Encoder input IDs: [1, 47, 86, 60, 68, 531, 1037, 385, 36, 2]\n",
            "Decoder input IDs: [1, 37, 42, 60, 89, 39, 259, 2914, 35, 2]\n",
            "Source text (decoded): ▁je ▁ne ▁suis ▁pas ▁aux ▁pie ces ▁.\n",
            "Target text (decoded): ▁i ▁m ▁not ▁in ▁a ▁r ush ▁.\n",
            "\n",
            "Example 2:\n",
            "Encoder input IDs: [1, 47, 86, 48, 883, 68, 239, 36, 2]\n",
            "Decoder input IDs: [1, 37, 42, 60, 1678, 501, 35, 2]\n",
            "Source text (decoded): ▁je ▁ne ▁d ors ▁pas ▁bien ▁.\n",
            "Target text (decoded): ▁i ▁m ▁not ▁sleeping ▁well ▁.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "def map_example(example: Dict[str, str]) -> Dict[str, List[int]]:\n",
        "    # TODO: Tokenize the source and target text for an entry in the parallel dataset\n",
        "    # and return a dictionary with the keys \"encoder_input_ids\" and \"decoder_input_ids\".\n",
        "    # You can use `source_tokenizer` and `target_tokenizer`\n",
        "    # Print example to understand its structure\n",
        "\n",
        "    # Tokenize the source text (French)\n",
        "    source_encoded = source_tokenizer(example[\"text_fr\"], truncation=True, padding='max_length') #trial:, max_length=128\n",
        "    # Tokenize the target text (English)\n",
        "    target_encoded = target_tokenizer(example[\"text_en\"], truncation=True, padding='max_length')\n",
        "\n",
        "    return {\n",
        "        \"encoder_input_ids\": source_encoded['input_ids'],\n",
        "        \"decoder_input_ids\": target_encoded['input_ids']\n",
        "    }\n",
        "\n",
        "# When mapped is applied to the DatasetDict object, it will apply `map` separately to each split.\n",
        "tokenized_datasets = raw_text_datasets.map(map_example, batched=False)\n",
        "\n",
        "# The `remove_columns` removes the existing text features from the new dataset, as they are no longer needed (OPTIMIZATION STEP).\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(raw_text_datasets.column_names[\"train\"])\n",
        "\n",
        "# Sanity checks on the new dataset\n",
        "assert set(tokenized_datasets.column_names[\"train\"]) == {\"decoder_input_ids\", \"encoder_input_ids\"}\n",
        "assert len(tokenized_datasets[\"train\"]) == len(raw_text_datasets[\"train\"])\n",
        "\n",
        "# ADDED SECTION! (NOTE THAT START OF SENTENCE HAS ID = 1 AND EOS HAS ID = 2)\n",
        "# Print a few examples to visualize and do a sanity check\n",
        "for i in range(3):\n",
        "    example = tokenized_datasets[\"train\"][i]\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"Encoder input IDs: {example['encoder_input_ids']}\")\n",
        "    print(f\"Decoder input IDs: {example['decoder_input_ids']}\")\n",
        "    print(\"Source text (decoded):\", source_tokenizer.decode(example['encoder_input_ids'], skip_special_tokens=True))\n",
        "    print(\"Target text (decoded):\", target_tokenizer.decode(example['decoder_input_ids'], skip_special_tokens=True))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3qPsuS71iIL"
      },
      "source": [
        "## Transformer model for NMT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R90j2WL61iIM"
      },
      "source": [
        "We will now implement a encoder-decoder transformer model.\n",
        "We already provide code for the Feedforward Layers and Transformer Blocks, but you will have to implement the MultiHeadAttention and Embedding layer from scratch, as well as registering all the layers in the final EncoderDecoderModel. Pay attention to doc-strings and typing information to understand the context and purpose of each missing code block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVjxNtLz1iIM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from typing import Optional, Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pMQHadt1iIM"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size: int,\n",
        "                 num_attention_heads: int,\n",
        "                 is_causal_attention: bool = False,\n",
        "                 is_cross_attention: bool = False):\n",
        "        \"\"\"Defines a flexible multi-head attention layer.\n",
        "\n",
        "        This layer should define parameters for the query, key and value projections, as well as the output projection,\n",
        "        and implement the following steps:\n",
        "        (1) Project the input vectors using query projection and key projection matrices.\n",
        "        (2) Compute the head-wise attention scores scaled by 1/sqrt(dk)\n",
        "        (3) Perform appropriate masking to the attention scores using key_padding_mask and optionally causal attention.\n",
        "        (4) Normalize the head-wise attention scores using softmax.\n",
        "        (5) Compute the value projections and then aggregate using the normalized attention scores.\n",
        "        (6) Use the output projection to obtain the final output vectors.\n",
        "        When is_cross_attention is True, the key and value projections are computed from the encoder outputs.\n",
        "        Note that we do not use attention weight dropout in this implementation.\n",
        "\n",
        "        Args:\n",
        "            hidden_size: The dimensionality of the input vectors.\n",
        "            num_attention_heads: The number of attention heads.\n",
        "            is_causal_attention: Whether to use causal masking,\n",
        "                    where tokens cannot attend to the future tokens on their right.\n",
        "            is_cross_attention: Whether to use cross attention,\n",
        "                    where we use different inputs for the key/value vs. query vectors.\n",
        "        \"\"\"\n",
        "        #Q = XWiQ ; K = XWiK ; V = XWVi (10.17)\n",
        "        # headi = SelfAttention(Q;K;V) (10.18)\n",
        "        # A = MultiHeadAttention(X) = (head1 ⊕head2:::⊕headh)WO (10.19)\n",
        "\n",
        "        super().__init__()\n",
        "        assert hidden_size % num_attention_heads == 0, \"The hidden size must be divisible by the number of attention heads.\"\n",
        "        self.dk = hidden_size // num_attention_heads  # embedding dimension of query and key vectors per head\n",
        "        self.is_cross_attention = is_cross_attention\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.is_causal_attention =is_causal_attention\n",
        "\n",
        "        # TODO Initialize the module and its parameters here.\n",
        "        # This module should be able to handle both full self-attention, causal masked self-attention and cross-attention.\n",
        "        # IMPORTANT: You are not allowed to use `nn.MultiheadAttention` or `nn.functional.scaled_dot_product_attention`!\n",
        "\n",
        "        # Q (n * dhidden )  *  WQ (dhidden  * dhidden) ==>  Q' (n * hidden)  split on dhidden  ==>\n",
        "        self.wq = nn.Linear(hidden_size, hidden_size)\n",
        "        self.wk = nn.Linear(hidden_size, hidden_size)\n",
        "        self.wv = nn.Linear(hidden_size, hidden_size)\n",
        "        self.wo = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # raise NotImplementedError(\"The __init__ function in TransformerAttention is not implemented yet.\")\n",
        "\n",
        "\n",
        "\n",
        "    def causal_attention_mask(self,\n",
        "                              sequence_length: int,\n",
        "                              device: Optional[torch.device] = None) -> torch.FloatTensor:\n",
        "        \"\"\"Return a Float tensor that can be added to the (un-normalized) attention scores for causal masking.\n",
        "\n",
        "        Args:\n",
        "            sequence_length: width and height of the attention mask tensor.\n",
        "            device: which torch device the resulting tensor should be on (important if you use GPU).\n",
        "\n",
        "        Returns:\n",
        "            A Float tensor of shape (1, 1, sequence_length, sequence_length) on device `device`,\n",
        "            where the entries above the diagonal contain large negative values,\n",
        "            which means that a query at position i can't attend to a key at position j>i.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement the forward function.\n",
        "        # IMPORTANT: For full credit, you should not use python loops.\n",
        "        #\n",
        "        # Hint 1: You can pick an arbitrary large value (e.g., -10^{6}), but note that\n",
        "        #         using `float(\"-inf\")` might lead to numerical issues and 'nan' values during training.\n",
        "        #\n",
        "        # Hint 2: Useful pytorch functions for this are `torch.arange` or `torch.triu`.\n",
        "        #\n",
        "        # Hint 3: You can move the tensor you create to a device by calling `tensor.to(device)`\n",
        "        #\n",
        "        # You should use this function in `forward` and use the returned tensor to implement causal masking\n",
        "        # by adding it to the un-normalized attention scores of shape (batch_size, num_heads, sequence_length, sequence_length),\n",
        "        # as torch will handle broadcasting and expand the first two dimensions to batch size and num_heads.\n",
        "        #\n",
        "        # You will the masking tensor to be on the same device as the attention scores's device,\n",
        "        # which you can via the attribute `tensor.device`.\n",
        "\n",
        "        mask = torch.triu(torch.full((1, 1, sequence_length, sequence_length), fill_value=-1e6, device=device), diagonal=1)\n",
        "       # mask = torch.triu(torch.ones((sequence_length, sequence_length), device=device) * float('-inf'), diagonal=1)\n",
        "        # return mask.unsqueeze(0).unsqueeze(0)  # (1, 1, sequence_length, sequence_length)\n",
        "\n",
        "        # torch.triu : btrg3 upper triagular matrix\n",
        "        # diagonal is the token with it self , (we need it (DONOT mask it))\n",
        "        # diagonal =1 -> ignore(skip) the main diagonal\n",
        "        # diagonal =2 -> skip the main diagoanal w wahed kman fo2o\n",
        "        # diagonal=3 -> ................. for more examples\n",
        "        # https://pytorch.org/docs/stable/generated/torch.triu.html\n",
        "\n",
        "        return mask\n",
        "\n",
        "        # raise NotImplementedError(\"The forward function in TransformerAttention is not implemented yet.\")\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                hidden_states: torch.FloatTensor,\n",
        "                key_padding_mask: torch.BoolTensor,\n",
        "                encoder_outputs: Optional[torch.FloatTensor] = None) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
        "        \"\"\"Computes scaled dot-product attention and returns the output of the attention layer.\n",
        "\n",
        "        Args:\n",
        "            hidden_states: Tensor of shape (batch_size, sequence_length, hidden_size) - the input vectors to the layer.\n",
        "            key_padding_mask: Tensor of shape (batch_size, sequence_length) indicating which tokens are padding tokens.\n",
        "                    A `True` entry means that this token should be ignored for the purpose of attention.\n",
        "                    In the case of cross-attention, the tensor has shape (batch_size, encoder_sequence_length).\n",
        "            encoder_outputs: Optional tensor of shape (batch_size, encoder_sequence_length, hidden_size).\n",
        "                    The output vectors of the encoder and only passed if the layer performs cross-attention.\n",
        "\n",
        "        Returns:\n",
        "            A (layer_output, attention_weights) where layer_output is a tensor of shape (batch_size, sequence_length, hidden_size)\n",
        "            and attention_weights are the normalized attention scores in the form of\n",
        "            a tensor of shape (batch_size, num_attention_heads, number_of_query_tokens, number_of_key_tokens).\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement the forward function.\n",
        "        # IMPORTANT: For full credit, you should not use python loops. Furthermore,\n",
        "        #            you are not allowed to use `nn.MultiheadAttention` or `nn.functional.scaled_dot_product_attention`!\n",
        "        #\n",
        "        # Hint 1: Use `torch.reshape` to add a new axis for the attention head,\n",
        "        #         which will allow you to process all attention heads in parallel.\n",
        "        #\n",
        "        # Hint 2: You can use `torch.transpose` to swap the order of two axes,\n",
        "        #         As the attention head dimension should be next to the batch size,\n",
        "        #         see the shape of the output attention weights.\n",
        "        #\n",
        "        # Hint 3: `torch.bmm(matrix1, matrix2)` is useful for computing batched matrix multiplications\n",
        "        #         If matrix1 has shape (B, M, N) and matrix2 has shape (B, N, P),\n",
        "        #         it performs `B` matrix multiplications and outputs a tensor of shape (B, M, P).\n",
        "        #         Alternatively, `torch.einsum` should be very useful.\n",
        "        #         (We really encourage you to check out the documentation of `torch.einsum`,\n",
        "        #         it can really make your life easier here.)\n",
        "\n",
        "        #  note :if cross attention (sequences mo5tlfa msh nfs el tol)\n",
        "################################################\n",
        "        # 1) define Q' , K' , V'\n",
        "        # hidden_states : the i/p vector to the layer  dimension :(batch_size, sequence_length, hidden_size)\n",
        "        query = self.wq(hidden_states) # (batch_size, sequence_length, hidden_size) -->(batch_size, sequence_length, hidden_size)\n",
        "        key = self.wk(hidden_states) if not self.is_cross_attention  else  self.wk(encoder_outputs) # lw ana cross-attention ha5od kwy & value mn o/p encoder\n",
        "        value = self.wv(hidden_states) if  not  self.is_cross_attention  else  self.wv(encoder_outputs)\n",
        "\n",
        "        # 2) Reshape for multi-head attention\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k) (kda b2t kol head shyfa kol el sentences bs msh kol el embedding)\n",
        "        # we want to split the third dimension (d_model)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.num_attention_heads , self.dk).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.num_attention_heads, self.dk).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.num_attention_heads, self.dk).transpose(1, 2)\n",
        "\n",
        "\n",
        "        # 3) Compute attention scores for each head\n",
        "        scores = torch.einsum(\"bhqd,bhkd->bhqk\", query, key) / math.sqrt(self.dk)\n",
        "        # attn_scores = torch.einsum(\"bhqd, bhkd -> bhqk\", query, key) / (self.head_dim ** 0.5)   # SCALE TO REDUCE DOT PRODUCT BIAS\n",
        "\n",
        "        '''\n",
        "        bhqd,bhkd->bhqk ,\n",
        "        el o/p mfrod yeb2a NxN lw ana shghal 3la sequences nfs el lenght\n",
        "        before transpose :query dim  -> (1,n,h,d-k)       key dim -> (1,m,h,d-k)    where n,m length of sequences\n",
        "\n",
        "        after transpose :query dim -> (1,h,n,d-k)        key dim  -> (1,h,m,d-k)\n",
        "\n",
        "        to calc attension scores mfrod enna hndrb Quer,key  b3d m3mlna transpose\n",
        "        (mfrod n3ks a5r 2 dimension lel key 3shan n3rf n3ml matrix multiplication)\n",
        "\n",
        "        bhqd,bhkd->bhqk  ,\n",
        "        b-> batch size\n",
        "        h-> h\n",
        "        q-> n (len of sent 1)\n",
        "        d-> d-k\n",
        "        k-> m (len of sent 2)\n",
        "        o/p : dimen (1,h,n,m)\n",
        "        '''\n",
        "\n",
        "        # 4) Apply mask if needed before softmax\n",
        "        # apply mask before the softmax lw ana decoder (msh 3yz ashof el future) , we donot want the padding value to interact with other values\n",
        "        '''\n",
        "        there are two senarios to apply the mask\n",
        "        1st : ana decoder (is_causal_attention == True) , msh 3yz abos 3l most2bl\n",
        "            bs ana b3ml kda f awl multihead , msh f tani wahda (cross-attention).s\n",
        "\n",
        "        2nd: we donot want the padding value to interact with other values.\n",
        "                In the 2nd senario , we have two cases with two diffrent dimension\n",
        "                    case not-cross attention :\n",
        "                        scores dim: (b,h,n,n)\n",
        "                        key_padding_mask dim :(b,n)\n",
        "                    case cross attention :\n",
        "                        scores dim: (b,h,n,m)\n",
        "                        key_padding_mask: (b,m)\n",
        "        '''\n",
        "        # 1st senario\n",
        "        if self.is_causal_attention:\n",
        "            causal_mask = self.causal_attention_mask(hidden_states.size(1), device=hidden_states.device)\n",
        "            # hidden_states : the i/p vector to the layer  dimension :(batch_size, sequence_length, hidden_size)\n",
        "            # ana 3ndi f decoder bb2a shagal 3la gomla n\n",
        "            # w bytl3li matrix n x n\n",
        "            # ana 3yz asfr el upper triangle in the matrix  , lw ana n x m t2rebn mfrod md5olsh 3la if condition da\n",
        "            scores.masked_fill_( causal_mask == -1e6  , -1e9 )\n",
        "\n",
        "        # 2nd senario\n",
        "        # Apply padding mask if provided  (batch_size, sequence_length) ==> bsize  * 1  * seq len  ==> bsize * 1 * 1 * seqlen\n",
        "        if key_padding_mask is not None:\n",
        "            scores = scores.masked_fill( key_padding_mask.unsqueeze(1).unsqueeze(2) , -1e9 ) # replace 3nd kol amakn el true , this value\n",
        "\n",
        "\n",
        "\n",
        "        # 5) Compute attention weights\n",
        "        attention_weights = torch.softmax(scores, dim=-1) # socres dim: (b,h,seq_len,seq_len)\n",
        "\n",
        "        # 6) Apply attention weights to values\n",
        "        # attention_weights dim: (b,h,n,n)   or  (b,h,n,m)\n",
        "        # value dim            : (1,h,n,d-k)  or (1,h,m,d-k)\n",
        "        attention_output = torch.matmul(attention_weights, value) # attention_output dim :(batch, h , seq_len, d_k)\n",
        "\n",
        "        # 7) Reshape and concatenate heads\n",
        "        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "        # hidden_states : the i/p vector to the layer  dimension : (batch_size, sequence_length, hidden_size)\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous().view( hidden_states.size(0),-1, hidden_states.size(-1) )\n",
        "\n",
        "        # 8) Apply output projection (multiply by wo)\n",
        "        output = self.wo(attention_output)\n",
        "\n",
        "        return output, attention_weights # attention weights for the visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNhiLcSw1iIM"
      },
      "source": [
        "Before we move on to the other modules, you should implement a sanity check for your attention implementation:\n",
        "1. We check the dimensions of the output of the layer and\n",
        "2. We plot the attention weights to some toy embedding inputs.\n",
        "We assume that the last token in the encoder and the last two tokens in the decoder are pad tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "epu_wgGi1iIM",
        "outputId": "2507c67c-13b0-4a58-bfa8-0d3518fb0c03"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "embed_dim = 8\n",
        "num_heads = 2\n",
        "batch_size = 1\n",
        "encoder_seq_length = 5\n",
        "decoder_seq_length = 7\n",
        "\n",
        "encoder_outputs = torch.randn(batch_size, encoder_seq_length, embed_dim)\n",
        "decoder_inputs = torch.randn(batch_size, decoder_seq_length, embed_dim)\n",
        "\n",
        "encoder_padding_mask = torch.zeros(batch_size, encoder_seq_length, dtype=torch.bool)\n",
        "encoder_padding_mask[:, -1] = True # The last encoder token is a padding tokens\n",
        "\n",
        "decoder_padding_mask = torch.zeros(batch_size, decoder_seq_length, dtype=torch.bool)\n",
        "decoder_padding_mask[:, -2:] = True # The last two decoder tokens are padding token\n",
        "\n",
        "\n",
        "cross_attention = MultiHeadAttention(embed_dim, num_heads, is_cross_attention=True )\n",
        "causal_attention = MultiHeadAttention(embed_dim, num_heads, is_causal_attention=True)\n",
        "# print(\"Hello i am cross attenttion\")\n",
        "cross_attention_out, cross_attention_weights = cross_attention(decoder_inputs, encoder_padding_mask, encoder_outputs)\n",
        "# print(\"Hello i am causal\")\n",
        "causal_attention_out, causal_attention_weights = causal_attention(decoder_inputs, decoder_padding_mask)\n",
        "\n",
        "# Make sure your outputs have the right hapes\n",
        "assert cross_attention_out.shape == (batch_size, decoder_seq_length, embed_dim)\n",
        "assert cross_attention_weights.shape == (batch_size, num_heads, decoder_seq_length, encoder_seq_length)\n",
        "assert causal_attention_out.shape == (batch_size, decoder_seq_length, embed_dim)\n",
        "assert causal_attention_weights.shape == (batch_size, num_heads, decoder_seq_length, decoder_seq_length)\n",
        "\n",
        "# Check that the attention weights are normalized\n",
        "assert torch.isclose(cross_attention_weights.sum(dim=-1), torch.tensor(1.0)).all()\n",
        "assert torch.isclose(causal_attention_weights.sum(dim=-1), torch.tensor(1.0)).all()\n",
        "\n",
        "# Check if the attention masking works\n",
        "assert torch.isclose(cross_attention_weights[:,:,:,-1], torch.tensor(0.0)).all()\n",
        "assert torch.isclose(causal_attention_weights[:,:,:,-2:], torch.tensor(0.0)).all()\n",
        "assert torch.isclose(causal_attention_weights[:,:,2,3:], torch.tensor(0.0)).all()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_attention_matrix(attention_matrix, title):\n",
        "    \"\"\"Creates a new figure and plots the normalized attention weights as a heatmap.\n",
        "\n",
        "    This should provide a colorbar for the scale of the heatmap and label the axes \"query token position\" and \"key token position\".\n",
        "    Args:\n",
        "        attention_matrix: A numpy array of shape (number_of_query_tokens, number_of_key_tokens)\n",
        "        title: The title of the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(attention_matrix, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Key token position')\n",
        "    plt.ylabel('Query token position')\n",
        "    plt.show()\n",
        "\n",
        "    # raise NotImplementedError(\"Plotting the attention weights is not implemented yet.\")\n",
        "\n",
        "plot_attention_matrix(cross_attention_weights[0,0].detach().numpy(), \"cross-attention, head 1\")\n",
        "plot_attention_matrix(cross_attention_weights[0,1].detach().numpy(), \"cross-attention, head 2\")\n",
        "plot_attention_matrix(causal_attention_weights[0,0].detach().numpy(), \"causal self-attention, head 1\")\n",
        "plot_attention_matrix(causal_attention_weights[0,1].detach().numpy(), \"causal self-attention, head 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d86pBrD71iIN"
      },
      "outputs": [],
      "source": [
        "class TransformerEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size: int, hidden_size: int, max_sequence_length: int):\n",
        "        \"\"\"Defines the embedding layer with learnt positional embeddings.\n",
        "\n",
        "        This layer defines both the token embeddings and positional embeddings,\n",
        "        which are added together to form the final embedding.\n",
        "\n",
        "        Args:\n",
        "            vocab_size: The size of the vocabulary,\n",
        "                    used to define the size of the token embedding table.\n",
        "\n",
        "            hidden_size: The dimensionality of the embedding space for both token embeddings and positional embeddings.\n",
        "\n",
        "            max_sequence_length: The maximum sequence length of the input sequences,\n",
        "                    used to define the size of the position embedding table.\n",
        "\n",
        "        Note that this implementation does not use dropout on the embeddings\n",
        "        and uses learnt positional embeddings instead of sinusoidal embeddings.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO Initialize the module and its parameters here.\n",
        "        # You should use `nn.Embedding` for both token embeddings and positional embeddings\n",
        "\n",
        "        # Initialize embeddings ,positional embeddings\n",
        "        self.emb = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.positional_embeddings = nn.Embedding(max_sequence_length, hidden_size) # (32,d_model)\n",
        "\n",
        "        # self.Emb_layer  = nn.Embedding( vocab_size  , hidden_size )\n",
        "        # pe = torch.zeros(max_sequence_length, hidden_size)\n",
        "        # # Create a vector of shape (seq_len)\n",
        "        # position = torch.arange(0, max_sequence_length, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
        "\n",
        "        # # Create a vector of shape (d_model)\n",
        "        # div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-math.log(10000.0) / hidden_size)) # (d_model / 2)\n",
        "\n",
        "        # # Apply sine to even indices\n",
        "        # pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n",
        "        # # Apply cosine to odd indices\n",
        "        # pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n",
        "\n",
        "\n",
        "        # # Add a batch dimension to the positional encoding\n",
        "        # pe = pe.unsqueeze(0) # (1, seq_len, d_model) mohm 3shan lma agi agm3 3la el empedings (empeding dimesion is .... (check forward function))\n",
        "        # # \"batch\" refers to a collection of input sequences processed together in parallel\n",
        "        # # during one iteration of training or inference\n",
        "        # # . Each sequence within the batch represents a single data sample.\n",
        "\n",
        "\n",
        "\n",
        "        # # Register the positional encoding as a buffer\n",
        "        # self.register_buffer('pe', pe)\n",
        "        # # Buffers in PyTorch are persistent and are part of the model's parameters, but they are not\n",
        "        # #updated during the optimization process like trainable parameters. Buffers are useful for storing persistent state\n",
        "        # # that doesn't require gradients, such as in this case where the positional\n",
        "        # #encoding is fixed and doesn't change during training\n",
        "\n",
        "\n",
        "\n",
        "        # # Define a linear layer to project decoder output to vocabulary space\n",
        "        # self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def compute_logits(self, decoder_output: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Computes the logits for the next token prediction given the decoder output.\n",
        "\n",
        "        Args:\n",
        "            decoder_output: Tensor of shape (batch_size, sequence_length, hidden_size) - the output of the decoder.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, vocab_size) containing the logits for the next token prediction.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement this function\n",
        "        # Hint: you can access the weight parameter matrix via .weight of an nn.Embedding module:\n",
        "        # Example:\n",
        "        # ```embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        # torch.matmul or F.linear may also be useful here.\n",
        "\n",
        "        logits = torch.matmul(decoder_output, self.emb.weight.t())\n",
        "        #  decoder_output: Tensor of shape (batch_size, sequence_length, hidden_size)\n",
        "        # seq len * hidden_size -> 3yz aprojecthom l size vocab (to predict next token)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def forward(self, input_ids: torch.LongTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Computes the embeddings for the input tokens.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Tensor of shape (batch_size, sequence_length) containing the input token ids.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, hidden_size) containing\n",
        "                    the sum of token embeddings and position embeddings for the input tokens.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # TODO Implement the forward pass of the embedding layer.\n",
        "        # IMPORTANT: For full credit, you should not use python loops!\n",
        "        batch_size, sequence_length = input_ids.size()\n",
        "        # 1) Compute  embeddings\n",
        "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
        "        token_embedded = self.emb(input_ids)  # (batch_size, sequence_length, hidden_size)\n",
        "\n",
        "        # 2) compute pos emb\n",
        "        # Generate positions\n",
        "        positions = torch.arange(self.max_sequence_length, device=input_ids.device).unsqueeze(0).expand(batch_size, -1) # batchsize  * max seq length\n",
        "        # torch.arange make 1-dim tensor (0 , max_sequence_length-1)\n",
        "        # This adds a dimension of size 1 at the beginning of the tensor.\n",
        "        # .expand(batch_size, -1): This duplicates the tensor along the batch dimension (0-th dimension) batch_size times.\n",
        "        # The -1 as the second argument tells PyTorch to keep the size of the second dimension the same as the original tensor\n",
        "        # we expand the tensor along the batch dimension while keeping the sequence length dimension unchanged.\n",
        "\n",
        "        positional_embedded = self.positional_embeddings(positions)  # (batch_size, sequence_length, hidden_size)\n",
        "        # Sum token embeddings and positional embeddings\n",
        "        embeddings = token_embedded + positional_embedded [: , :sequence_length  , : ]\n",
        "\n",
        "\n",
        "        # how to make positional emb learnable ??!!! , define a weighted matrix wp?\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "        # Multiply by sqrt(d_model) to scale the embeddings according to the paper\n",
        "        # (batch, seq_len) --> (batch, seq_len, d_model)    each batch : ((rows :kol kelma(token) , 2osdha empeding vector bt3ha ))\n",
        "        # EMB  =  self.embedding(input_ids) * math.sqrt(self.d_model) # hy3wd 3n kol id b empeding bta3o\n",
        "\n",
        "        # # 3yz a3m element wise additon , pe dimensions is (1,max seq length,d_model)\n",
        "        # EMB = EMB + (self.pe[: ,  :input_ids.shape[1] , :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
        "        # # :  --> selects all the batches , tb h3ml 3lehom eh ?\n",
        "        # # :input_ids.shape[1] --> for each batch ,ana bbos 3la (batch mn EMB w batch mn pe) 3yz agm3hom element wise\n",
        "        # # f lazm azbt dimension pe , azbtha teb2a ad el batch l f EMB\n",
        "        # # pe dimensions is (1,max seq length,d_model) , 3yz azbt el maxSeqLen da a5lyh b tol l seq l ana w2f 3ndo\n",
        "        # # f ha5od mn awl row till row (N(len of sequence)) , and then access all the columns (d_model) using :\n",
        "\n",
        "        # # pe  (batch: akno 2d matrix)\n",
        "        # # each of the 2d matrix has diffrent (seq length(N))\n",
        "        # # .requires_grad_(False) : b2ol lel model dol msh learnable parameters (el tensor da will not learn)\n",
        "        # return EMB\n",
        "\n",
        "        # raise NotImplementedError(\"The forward function in TransformerEmbeddings is not implemented yet.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFW-eNNB1iIN"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size: int,\n",
        "                 intermediate_size: int,\n",
        "                 num_attention_heads: int,\n",
        "                 hidden_dropout_prob: float,\n",
        "                 is_decoder: bool = False):\n",
        "        \"\"\"Defines a single Transformer block, which can be either for the encoder or the decoder.\n",
        "\n",
        "        Args:\n",
        "            hidden_size: The dimensionality of the input and output vectors of this layer.\n",
        "            intermediate_size: The intermediate size of the feedforward layers.\n",
        "            num_attention_heads: The number of attention heads.\n",
        "            hidden_dropout_prob: The dropout probability for the hidden states.\n",
        "            is_decoder: Whether this block is part of the decoder.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # see the transformer block for visualization\n",
        "        self.is_decoder = is_decoder\n",
        "        self.self_attention = MultiHeadAttention(hidden_size, num_attention_heads, is_causal_attention=is_decoder)\n",
        "        self.self_attention_layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        if is_decoder:\n",
        "            self.cross_attention = MultiHeadAttention(hidden_size, num_attention_heads, is_cross_attention=True)\n",
        "            self.cross_attention_layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(hidden_size, intermediate_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(intermediate_size, hidden_size),\n",
        "            nn.Dropout(hidden_dropout_prob))\n",
        "        self.feedforward_layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                hidden_states: torch.FloatTensor,\n",
        "                padding_mask: torch.BoolTensor,\n",
        "                encoder_outputs: Optional[torch.FloatTensor] = None,\n",
        "                encoder_padding_mask: Optional[torch.BoolTensor] = None) -> torch.FloatTensor:\n",
        "        \"\"\"Defines a single Transformer block, either for the encoder or the decoder.\n",
        "\n",
        "        Args:\n",
        "            hidden_states: Tensor of shape (batch_size, sequence_length, hidden_size) - the outputs from the previous layer.\n",
        "            padding_mask: Tensor of shape (batch_size, sequence_length) indicating which tokens are padding tokens.\n",
        "                    A `True` entry means that this token should be ignored for the purpose of attention.\n",
        "            encoder_outputs: Optional tensor of shape (batch_size, encoder_sequence_length, hidden_size),\n",
        "                    which are the output vectors of the encoder. This argument is only used by decoder blocks.\n",
        "            encoder_padding_mask: Optional tensor of shape (batch_size, encoder_sequence_length) indicating\n",
        "                    which encoder tokens are padding tokens. This argument is only used in decoder blocks.\n",
        "                    A `True` entry means that this token should be ignored for the purpose of attention.\n",
        "\n",
        "        \"\"\"\n",
        "        hidden_states = self.self_attention(hidden_states, padding_mask)[0] + hidden_states\n",
        "        # goz2 (+hiddenstates) da hwa el residual connection\n",
        "        # hna hwa 3ml +hidden states abl el layer normalization\n",
        "        hidden_states = self.self_attention_layer_norm(hidden_states)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            hidden_states = self.cross_attention(hidden_states, encoder_padding_mask, encoder_outputs)[0] + hidden_states\n",
        "            # hna b3t encoder_padding_mask , 3shan , fel matrix l bn3mlha fo2 f cross attention btkon of dim : (seq len of decoder , seq len of encoder)\n",
        "            hidden_states = self.cross_attention_layer_norm(hidden_states)\n",
        "\n",
        "        hidden_states = self.feedforward(hidden_states) + hidden_states\n",
        "        hidden_states = self.feedforward_layer_norm(hidden_states)\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC_EQSQ51iIN"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 source_vocab_size: int,\n",
        "                 target_vocab_size: int,\n",
        "                 hidden_size: int,\n",
        "                 intermediate_size: int,\n",
        "                 num_attention_heads: int,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 max_sequence_length: int,\n",
        "                 hidden_dropout_prob: float):\n",
        "        \"\"\"A encoder-decoder transformer model which can be used for NMT.\n",
        "\n",
        "        Args:\n",
        "            source_vocab_size: The size of the source vocabulary.\n",
        "            target_vocab_size: The size of the target vocabulary.\n",
        "            hidden_size: The dimensionality of all input and output embeddings.\n",
        "            intermediate_size: The intermediate size in the feedforward layers.\n",
        "            num_attention_heads: The number of attention heads in each multi-head attention modules.\n",
        "            num_encoder_layers: The number of transformer blocks in the encoder.\n",
        "            num_decoder_layers: The number of transformer blocks in the decoder.\n",
        "            max_sequence_length: The maximum sequence length that this model can handle.\n",
        "            hidden_dropout_prob: The dropout probability in the hidden state in each block.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        # TODO Register the input embedding modules and the encoder and decoder blocks.\n",
        "        # You should use the TransformerBlock and TransformerEmbeddings sub-modules.\n",
        "        # Hint: Check out `nn.ModuleList` to register a variable number of sub-modules.\n",
        "\n",
        "        # Input embeddings\n",
        "        # print(f\"Hello yossfffff {max_sequence_length}\") --> 32\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.encoder_embeddings = TransformerEmbeddings(source_vocab_size, hidden_size, max_sequence_length)\n",
        "        self.decoder_embeddings = TransformerEmbeddings(target_vocab_size, hidden_size, max_sequence_length)\n",
        "\n",
        "        # Encoder , el transformer block da bytkrr kza mra\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TransformerBlock(hidden_size, intermediate_size, num_attention_heads, hidden_dropout_prob)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.ModuleList([\n",
        "            TransformerBlock(hidden_size, intermediate_size, num_attention_heads, hidden_dropout_prob,is_decoder=True)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "\n",
        "        # raise NotImplementedError(\"The __init__ function is not implemented yet.\")\n",
        "\n",
        "    def forward_encoder(self, input_ids: torch.LongTensor, padding_mask: torch.BoolTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Implement the forward pass of the encoder.\n",
        "\n",
        "        Args:\n",
        "            input_ids: tensor of shape (batch_size, sequence_length) containing the input token ids to the encoder.\n",
        "            padding_mask: tensor of shape (batch_size, sequence_length) indicating which encoder tokens are padding tokens (`True`)\n",
        "                    and should be ignored in self-attention computations.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, hidden_size) containing the output embeddings of the encoder.\n",
        "        \"\"\"\n",
        "\n",
        "        # # TODO Implement this function\n",
        "        batchsize  ,  sequence_length  = input_ids.size()\n",
        "        # Get input embeddings\n",
        "        # input_ids = input_ids [: , : self.max_sequence_length]   if sequence_length > self.max_sequence_length else input_ids\n",
        "\n",
        "        encoder_embeddings = self.encoder_embeddings(input_ids)  # (batch_size, sequence_length, hidden_size)\n",
        "        # Forward pass through encoder blocks\n",
        "        encoder_hidden_states = encoder_embeddings\n",
        "        for block in self.encoder:\n",
        "            encoder_hidden_states = block(encoder_hidden_states, padding_mask)\n",
        "\n",
        "        return encoder_hidden_states\n",
        "\n",
        "        # raise NotImplementedError(\"The forward_encoder function is not implemented yet.\")\n",
        "\n",
        "    def forward_decoder(self,\n",
        "                        input_ids: torch.LongTensor,\n",
        "                        padding_mask: torch.BoolTensor,\n",
        "                        encoder_outputs: torch.FloatTensor,\n",
        "                        encoder_padding_mask: torch.BoolTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Implement the forward pass of the decoder.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Tensor of shape (batch_size, sequence_length) containing the input token ids to the decoder.\n",
        "            padding_mask: Tensor of shape (batch_size, sequence_length) indicating which decoder tokens are padding tokens (`True`)\n",
        "                    and should be ignored in self-attention computations.\n",
        "            encoder_outputs: Tensor of shape (batch_size, encoder_sequence_length, hidden_size) containing the output embeddings of the encoder.\n",
        "            encoder_padding_mask: Tensor of shape (batch_size, encoder_sequence_length) indicating which encoder tokens are padding tokens (`True`)\n",
        "                    and should be ignored in cross-attention computations.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, target_vocabulary_size)\n",
        "            containing the logits for predicting the next token in the target sequence.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement this function\n",
        "        batch_size, sequence_length = input_ids.size()\n",
        "\n",
        "\n",
        "        # Get input embeddings\n",
        "        decoder_embeddings = self.decoder_embeddings(input_ids)\n",
        "        decoder_hidden_states = decoder_embeddings\n",
        "\n",
        "        for block in self.decoder:\n",
        "            decoder_hidden_states = block(\n",
        "                decoder_hidden_states, padding_mask,\n",
        "                encoder_outputs, encoder_padding_mask)\n",
        "\n",
        "        # Compute logits\n",
        "        logits = self.decoder_embeddings.compute_logits(decoder_hidden_states)\n",
        "\n",
        "\n",
        "\n",
        "        return logits\n",
        "        # raise NotImplementedError(\"The forward_decoder function has to be implemented.\")\n",
        "\n",
        "    def forward(self, encoder_input_ids, encoder_padding_mask, decoder_input_ids, decoder_padding_mask):\n",
        "        encoder_outputs = self.forward_encoder(encoder_input_ids, encoder_padding_mask)\n",
        "        decoder_logits = self.forward_decoder(decoder_input_ids, decoder_padding_mask, encoder_outputs, encoder_padding_mask)\n",
        "        return decoder_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbf1FkZteHIW"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "In this section, we train the seq2seq model on the parallel tokenized corpus.\n",
        "Before you start training models, you should implement and test the model and its sub-modules, especially the attention.\n",
        "\n",
        "First, we implement a `collate` function, which takes a list of examples from the dataset and forms a batch,\n",
        "consisting of padded encoder and decoder input ids, as well as encoder and decoder padding masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VknfRSbb1iIN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(examples: List[Dict[str, List[int]]]) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Collates a list of variable length sequences from the dataset into a batch of pytorch tensors with padding.\"\"\"\n",
        "\n",
        "    encoder_sequence_length = max(len(example[\"encoder_input_ids\"]) for example in examples)\n",
        "    decoder_sequence_length = max(len(example[\"decoder_input_ids\"]) for example in examples)\n",
        "    batch_size = len(examples)\n",
        "\n",
        "    encoder_input_ids = torch.full((batch_size, encoder_sequence_length),\n",
        "                                   fill_value=source_tokenizer.pad_token_id,\n",
        "                                   dtype=torch.int64)\n",
        "    encoder_padding_mask = torch.ones((batch_size, encoder_sequence_length),\n",
        "                                      dtype=torch.bool)\n",
        "\n",
        "    decoder_input_ids = torch.full((batch_size, decoder_sequence_length),\n",
        "                                   fill_value=target_tokenizer.pad_token_id,\n",
        "                                   dtype=torch.int64)\n",
        "    decoder_padding_mask = torch.ones((batch_size, decoder_sequence_length),\n",
        "                                      dtype=torch.bool)\n",
        "    # print(f\"examples =>{examples}\")\n",
        "    # print(f\"examples =>{examples.size()}\")\n",
        "    for i, example in enumerate(examples):\n",
        "        encoder_input_ids[i, :len(example[\"encoder_input_ids\"])] = torch.tensor(example[\"encoder_input_ids\"])\n",
        "        encoder_padding_mask[i, :len(example[\"encoder_input_ids\"])] = False\n",
        "\n",
        "        decoder_input_ids[i, :len(example[\"decoder_input_ids\"])] = torch.tensor(example[\"decoder_input_ids\"])\n",
        "        decoder_padding_mask[i, :len(example[\"decoder_input_ids\"])] = False\n",
        "\n",
        "    return {\"encoder_input_ids\": encoder_input_ids,\n",
        "            \"encoder_padding_mask\": encoder_padding_mask,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"decoder_padding_mask\": decoder_padding_mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgp3PZL21iIN"
      },
      "source": [
        "Next, we provide a simple training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeZgvg2VkRQd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def compute_loss_per_token(model, batch):\n",
        "    logits = model(**batch)\n",
        "\n",
        "    valid_label_mask = ~(batch[\"decoder_padding_mask\"][:,1:])\n",
        "    # print(f\"valid label mask dims are {valid_label_mask.size()}\")\n",
        "    labels = batch[\"decoder_input_ids\"][:,1:][valid_label_mask]\n",
        "    # print(f\"logits sizes are {logits.size()}\")\n",
        "    logits = logits[:,:-1][valid_label_mask]\n",
        "\n",
        "\n",
        "    return F.cross_entropy(logits, labels, reduction='none')\n",
        "\n",
        "\n",
        "def evaluate_perplexity(model, dataset, batch_size=32, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    dev_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    num_tokens = loss_sum = 0\n",
        "\n",
        "    # no_grad() signals backend to throw away all gradients\n",
        "    with torch.no_grad():\n",
        "        for batch in dev_loader:\n",
        "            # Move tensors in batch to device\n",
        "            for key in batch:\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "            token_losses = compute_loss_per_token(model, batch)\n",
        "\n",
        "            loss_sum += token_losses.sum()\n",
        "            num_tokens += token_losses.numel()\n",
        "\n",
        "        dev_ppl = (loss_sum / num_tokens).exp().cpu().item()\n",
        "    return dev_ppl\n",
        "\n",
        "\n",
        "def train(model, training_dataset, validation_dataset,\n",
        "          batch_size=32, lr=1e-3, max_epoch=10, log_every=10, valid_niter=100,\n",
        "          model_path=\"model.pt\"):\n",
        "    model.train()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Use device: %s' % device)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    epoch = global_step = loss_sum = num_tokens = num_examples = 0\n",
        "    best_valid_perplexity = float('inf')\n",
        "    train_time = begin_time = time.time()\n",
        "    print('Beginning maximum likelihood training')\n",
        "    max_seq_len_encoder  =  0\n",
        "    max_seq_len_deccoder  =  0\n",
        "\n",
        "    while True:\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            training_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "        epoch += 1\n",
        "        batches_per_epoch = len(train_loader)\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            global_step += 1\n",
        "\n",
        "            # Move tensors in batch to device\n",
        "            for key in batch:\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            token_losses = compute_loss_per_token(model, batch)\n",
        "            total_loss = token_losses.sum()\n",
        "\n",
        "            loss = total_loss / batch_size\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_sum += total_loss.cpu().item()\n",
        "            num_tokens += token_losses.numel()\n",
        "            num_examples += batch_size\n",
        "\n",
        "            if global_step % log_every == 0:\n",
        "                average_loss = loss_sum / num_examples\n",
        "                average_ppl = math.exp(loss_sum / num_tokens)\n",
        "                print(f\"epoch {epoch} ({i}/{batches_per_epoch}) | step {global_step} | \"\n",
        "                      f\"avg_nll={average_loss:.2f} avg_ppl={average_ppl:.2f} \"\n",
        "                      f\"speed={num_tokens / (time.time() - train_time):.2f} words/sec \"\n",
        "                      f\"time_elapsed={time.time() - begin_time:.2f} sec\")\n",
        "\n",
        "                train_time = time.time()\n",
        "                loss_sum = num_tokens = num_examples = 0.0\n",
        "\n",
        "            if global_step % valid_niter == 0:\n",
        "                print('Begin validation ...')\n",
        "                dev_perplexity = evaluate_perplexity(model, validation_dataset, batch_size=batch_size, device=device)\n",
        "\n",
        "                print(f\"validation: step {global_step} | dev_ppl={dev_perplexity}\")\n",
        "\n",
        "                if dev_perplexity < best_valid_perplexity:\n",
        "                    best_valid_perplexity = dev_perplexity\n",
        "                    print(f\"epoch {epoch} step {global_step}: save currently the best model to '{model_path}'\")\n",
        "                    torch.save(model.state_dict(), model_path)\n",
        "                    torch.save(optimizer.state_dict(), model_path + '.optim')\n",
        "                model.train()\n",
        "\n",
        "        if epoch == max_epoch:\n",
        "            print('Reached maximum number of epochs')\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8NLae1r1iIO"
      },
      "source": [
        "Let's train a relatively small model architecture for 15 epochs.\n",
        "With a reasonable implementation, this should take about 16 minutes on CPU / 3 minutes on GPU and we should achieve a validation perplexity of below 10!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j8KNRx21iIO",
        "outputId": "1a7d9e01-b3b8-4b47-8618-5a144a006822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture: EncoderDecoderModel(\n",
            "  (encoder_embeddings): TransformerEmbeddings(\n",
            "    (emb): Embedding(3200, 32)\n",
            "    (positional_embeddings): Embedding(32, 32)\n",
            "  )\n",
            "  (decoder_embeddings): TransformerEmbeddings(\n",
            "    (emb): Embedding(3200, 32)\n",
            "    (positional_embeddings): Embedding(32, 32)\n",
            "  )\n",
            "  (encoder): ModuleList(\n",
            "    (0-2): 3 x TransformerBlock(\n",
            "      (self_attention): MultiHeadAttention(\n",
            "        (wq): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wk): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wv): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wo): Linear(in_features=32, out_features=32, bias=True)\n",
            "      )\n",
            "      (self_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      (feedforward): Sequential(\n",
            "        (0): Linear(in_features=32, out_features=128, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=128, out_features=32, bias=True)\n",
            "        (3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feedforward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): ModuleList(\n",
            "    (0-2): 3 x TransformerBlock(\n",
            "      (self_attention): MultiHeadAttention(\n",
            "        (wq): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wk): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wv): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wo): Linear(in_features=32, out_features=32, bias=True)\n",
            "      )\n",
            "      (self_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      (cross_attention): MultiHeadAttention(\n",
            "        (wq): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wk): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wv): Linear(in_features=32, out_features=32, bias=True)\n",
            "        (wo): Linear(in_features=32, out_features=32, bias=True)\n",
            "      )\n",
            "      (cross_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      (feedforward): Sequential(\n",
            "        (0): Linear(in_features=32, out_features=128, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=128, out_features=32, bias=True)\n",
            "        (3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feedforward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of trainable model parameters: 295936\n",
            "We are in datasets train\n",
            "Dataset({\n",
            "    features: ['encoder_input_ids', 'decoder_input_ids'],\n",
            "    num_rows: 8701\n",
            "})\n",
            "Use device: cuda\n",
            "Beginning maximum likelihood training\n",
            "epoch 1 (9/272) | step 10 | avg_nll=116.93 avg_ppl=9236023.95 speed=1301.50 words/sec time_elapsed=1.79 sec\n",
            "epoch 1 (19/272) | step 20 | avg_nll=84.01 avg_ppl=130601.13 speed=9719.86 words/sec time_elapsed=2.03 sec\n",
            "epoch 1 (29/272) | step 30 | avg_nll=78.84 avg_ppl=62402.68 speed=9567.94 words/sec time_elapsed=2.27 sec\n",
            "epoch 1 (39/272) | step 40 | avg_nll=73.53 avg_ppl=25184.10 speed=10141.75 words/sec time_elapsed=2.50 sec\n",
            "epoch 1 (49/272) | step 50 | avg_nll=67.80 avg_ppl=10062.20 speed=9835.37 words/sec time_elapsed=2.73 sec\n",
            "epoch 1 (59/272) | step 60 | avg_nll=62.01 avg_ppl=4433.46 speed=9726.49 words/sec time_elapsed=2.98 sec\n",
            "epoch 1 (69/272) | step 70 | avg_nll=53.80 avg_ppl=1770.76 speed=9339.31 words/sec time_elapsed=3.22 sec\n",
            "epoch 1 (79/272) | step 80 | avg_nll=51.08 avg_ppl=1151.32 speed=7986.72 words/sec time_elapsed=3.51 sec\n",
            "epoch 1 (89/272) | step 90 | avg_nll=49.18 avg_ppl=896.07 speed=6910.26 words/sec time_elapsed=3.85 sec\n",
            "epoch 1 (99/272) | step 100 | avg_nll=46.45 avg_ppl=618.25 speed=7396.54 words/sec time_elapsed=4.16 sec\n",
            "Begin validation ...\n",
            "validation: step 100 | dev_ppl=418.98480224609375\n",
            "epoch 1 step 100: save currently the best model to 'model.pt'\n",
            "epoch 1 (109/272) | step 110 | avg_nll=44.26 avg_ppl=455.29 speed=4048.51 words/sec time_elapsed=4.74 sec\n",
            "epoch 1 (119/272) | step 120 | avg_nll=43.06 avg_ppl=378.50 speed=6688.16 words/sec time_elapsed=5.08 sec\n",
            "epoch 1 (129/272) | step 130 | avg_nll=42.61 avg_ppl=334.37 speed=6786.52 words/sec time_elapsed=5.43 sec\n",
            "epoch 1 (139/272) | step 140 | avg_nll=38.75 avg_ppl=228.35 speed=6596.97 words/sec time_elapsed=5.78 sec\n",
            "epoch 1 (149/272) | step 150 | avg_nll=37.68 avg_ppl=194.06 speed=6688.46 words/sec time_elapsed=6.12 sec\n",
            "epoch 1 (159/272) | step 160 | avg_nll=36.79 avg_ppl=170.03 speed=7834.71 words/sec time_elapsed=6.41 sec\n",
            "epoch 1 (169/272) | step 170 | avg_nll=34.43 avg_ppl=130.18 speed=9914.13 words/sec time_elapsed=6.64 sec\n",
            "epoch 1 (179/272) | step 180 | avg_nll=35.58 avg_ppl=134.95 speed=10164.93 words/sec time_elapsed=6.87 sec\n",
            "epoch 1 (189/272) | step 190 | avg_nll=33.51 avg_ppl=107.82 speed=10000.73 words/sec time_elapsed=7.10 sec\n",
            "epoch 1 (199/272) | step 200 | avg_nll=33.45 avg_ppl=101.90 speed=9812.32 words/sec time_elapsed=7.34 sec\n",
            "Begin validation ...\n",
            "validation: step 200 | dev_ppl=89.6078872680664\n",
            "epoch 1 step 200: save currently the best model to 'model.pt'\n",
            "epoch 1 (209/272) | step 210 | avg_nll=34.82 avg_ppl=107.16 speed=5922.55 words/sec time_elapsed=7.74 sec\n",
            "epoch 1 (219/272) | step 220 | avg_nll=33.21 avg_ppl=98.57 speed=9963.77 words/sec time_elapsed=7.97 sec\n",
            "epoch 1 (229/272) | step 230 | avg_nll=32.91 avg_ppl=90.29 speed=9963.09 words/sec time_elapsed=8.21 sec\n",
            "epoch 1 (239/272) | step 240 | avg_nll=32.74 avg_ppl=86.48 speed=9802.69 words/sec time_elapsed=8.45 sec\n",
            "epoch 1 (249/272) | step 250 | avg_nll=32.74 avg_ppl=86.72 speed=9873.39 words/sec time_elapsed=8.68 sec\n",
            "epoch 1 (259/272) | step 260 | avg_nll=30.61 avg_ppl=69.33 speed=10005.66 words/sec time_elapsed=8.92 sec\n",
            "epoch 1 (269/272) | step 270 | avg_nll=29.70 avg_ppl=61.72 speed=9737.10 words/sec time_elapsed=9.15 sec\n",
            "epoch 2 (7/272) | step 280 | avg_nll=28.25 avg_ppl=53.81 speed=8711.98 words/sec time_elapsed=9.41 sec\n",
            "epoch 2 (17/272) | step 290 | avg_nll=29.18 avg_ppl=57.35 speed=9770.23 words/sec time_elapsed=9.65 sec\n",
            "epoch 2 (27/272) | step 300 | avg_nll=29.04 avg_ppl=55.47 speed=9431.49 words/sec time_elapsed=9.90 sec\n",
            "Begin validation ...\n",
            "validation: step 300 | dev_ppl=49.20067596435547\n",
            "epoch 2 step 300: save currently the best model to 'model.pt'\n",
            "epoch 2 (37/272) | step 310 | avg_nll=28.80 avg_ppl=53.78 speed=5668.31 words/sec time_elapsed=10.30 sec\n",
            "epoch 2 (47/272) | step 320 | avg_nll=28.33 avg_ppl=50.01 speed=9565.75 words/sec time_elapsed=10.55 sec\n",
            "epoch 2 (57/272) | step 330 | avg_nll=27.12 avg_ppl=43.19 speed=9721.62 words/sec time_elapsed=10.78 sec\n",
            "epoch 2 (67/272) | step 340 | avg_nll=28.17 avg_ppl=47.58 speed=10165.41 words/sec time_elapsed=11.01 sec\n",
            "epoch 2 (77/272) | step 350 | avg_nll=28.12 avg_ppl=46.01 speed=10016.99 words/sec time_elapsed=11.25 sec\n",
            "epoch 2 (87/272) | step 360 | avg_nll=27.57 avg_ppl=45.83 speed=9759.40 words/sec time_elapsed=11.49 sec\n",
            "epoch 2 (97/272) | step 370 | avg_nll=27.93 avg_ppl=43.47 speed=9843.12 words/sec time_elapsed=11.73 sec\n",
            "epoch 2 (107/272) | step 380 | avg_nll=26.24 avg_ppl=38.52 speed=10201.46 words/sec time_elapsed=11.95 sec\n",
            "epoch 2 (117/272) | step 390 | avg_nll=25.31 avg_ppl=35.25 speed=9007.88 words/sec time_elapsed=12.20 sec\n",
            "epoch 2 (127/272) | step 400 | avg_nll=24.42 avg_ppl=33.02 speed=9701.62 words/sec time_elapsed=12.44 sec\n",
            "Begin validation ...\n",
            "validation: step 400 | dev_ppl=35.834251403808594\n",
            "epoch 2 step 400: save currently the best model to 'model.pt'\n",
            "epoch 2 (137/272) | step 410 | avg_nll=26.01 avg_ppl=35.77 speed=5647.01 words/sec time_elapsed=12.85 sec\n",
            "epoch 2 (147/272) | step 420 | avg_nll=28.01 avg_ppl=43.86 speed=10215.59 words/sec time_elapsed=13.08 sec\n",
            "epoch 2 (157/272) | step 430 | avg_nll=25.17 avg_ppl=33.33 speed=9594.69 words/sec time_elapsed=13.32 sec\n",
            "epoch 2 (167/272) | step 440 | avg_nll=26.07 avg_ppl=35.28 speed=9397.15 words/sec time_elapsed=13.57 sec\n",
            "epoch 2 (177/272) | step 450 | avg_nll=26.66 avg_ppl=36.98 speed=9794.84 words/sec time_elapsed=13.81 sec\n",
            "epoch 2 (187/272) | step 460 | avg_nll=24.93 avg_ppl=31.60 speed=10151.68 words/sec time_elapsed=14.04 sec\n",
            "epoch 2 (197/272) | step 470 | avg_nll=24.33 avg_ppl=29.52 speed=9853.90 words/sec time_elapsed=14.27 sec\n",
            "epoch 2 (207/272) | step 480 | avg_nll=24.83 avg_ppl=31.65 speed=9586.16 words/sec time_elapsed=14.51 sec\n",
            "epoch 2 (217/272) | step 490 | avg_nll=24.82 avg_ppl=31.32 speed=10016.20 words/sec time_elapsed=14.74 sec\n",
            "epoch 2 (227/272) | step 500 | avg_nll=25.64 avg_ppl=32.93 speed=10438.37 words/sec time_elapsed=14.97 sec\n",
            "Begin validation ...\n",
            "validation: step 500 | dev_ppl=28.798442840576172\n",
            "epoch 2 step 500: save currently the best model to 'model.pt'\n",
            "epoch 2 (237/272) | step 510 | avg_nll=26.24 avg_ppl=35.94 speed=5843.50 words/sec time_elapsed=15.37 sec\n",
            "epoch 2 (247/272) | step 520 | avg_nll=24.37 avg_ppl=29.73 speed=9746.33 words/sec time_elapsed=15.60 sec\n",
            "epoch 2 (257/272) | step 530 | avg_nll=24.76 avg_ppl=31.51 speed=9775.02 words/sec time_elapsed=15.84 sec\n",
            "epoch 2 (267/272) | step 540 | avg_nll=25.17 avg_ppl=31.19 speed=9803.23 words/sec time_elapsed=16.08 sec\n",
            "epoch 3 (5/272) | step 550 | avg_nll=24.10 avg_ppl=27.55 speed=9013.53 words/sec time_elapsed=16.34 sec\n",
            "epoch 3 (15/272) | step 560 | avg_nll=24.96 avg_ppl=30.01 speed=6809.61 words/sec time_elapsed=16.68 sec\n",
            "epoch 3 (25/272) | step 570 | avg_nll=23.64 avg_ppl=26.14 speed=7416.61 words/sec time_elapsed=16.99 sec\n",
            "epoch 3 (35/272) | step 580 | avg_nll=23.62 avg_ppl=25.84 speed=7161.38 words/sec time_elapsed=17.32 sec\n",
            "epoch 3 (45/272) | step 590 | avg_nll=22.96 avg_ppl=24.77 speed=6835.71 words/sec time_elapsed=17.65 sec\n",
            "epoch 3 (55/272) | step 600 | avg_nll=23.75 avg_ppl=26.94 speed=6696.12 words/sec time_elapsed=18.00 sec\n",
            "Begin validation ...\n",
            "validation: step 600 | dev_ppl=24.721269607543945\n",
            "epoch 3 step 600: save currently the best model to 'model.pt'\n",
            "epoch 3 (65/272) | step 610 | avg_nll=23.64 avg_ppl=25.59 speed=3925.87 words/sec time_elapsed=18.59 sec\n",
            "epoch 3 (75/272) | step 620 | avg_nll=22.55 avg_ppl=24.46 speed=6405.25 words/sec time_elapsed=18.95 sec\n",
            "epoch 3 (85/272) | step 630 | avg_nll=23.22 avg_ppl=24.65 speed=7996.63 words/sec time_elapsed=19.24 sec\n",
            "epoch 3 (95/272) | step 640 | avg_nll=23.12 avg_ppl=24.09 speed=9168.44 words/sec time_elapsed=19.49 sec\n",
            "epoch 3 (105/272) | step 650 | avg_nll=23.69 avg_ppl=24.86 speed=9334.92 words/sec time_elapsed=19.74 sec\n",
            "epoch 3 (115/272) | step 660 | avg_nll=23.17 avg_ppl=24.84 speed=10279.05 words/sec time_elapsed=19.97 sec\n",
            "epoch 3 (125/272) | step 670 | avg_nll=22.12 avg_ppl=22.25 speed=10145.29 words/sec time_elapsed=20.19 sec\n",
            "epoch 3 (135/272) | step 680 | avg_nll=23.83 avg_ppl=25.82 speed=10229.00 words/sec time_elapsed=20.42 sec\n",
            "epoch 3 (145/272) | step 690 | avg_nll=23.90 avg_ppl=26.30 speed=9794.98 words/sec time_elapsed=20.66 sec\n",
            "epoch 3 (155/272) | step 700 | avg_nll=23.93 avg_ppl=26.09 speed=9508.96 words/sec time_elapsed=20.91 sec\n",
            "Begin validation ...\n",
            "validation: step 700 | dev_ppl=22.351757049560547\n",
            "epoch 3 step 700: save currently the best model to 'model.pt'\n",
            "epoch 3 (165/272) | step 710 | avg_nll=23.05 avg_ppl=23.75 speed=5779.39 words/sec time_elapsed=21.31 sec\n",
            "epoch 3 (175/272) | step 720 | avg_nll=22.52 avg_ppl=21.97 speed=9903.28 words/sec time_elapsed=21.55 sec\n",
            "epoch 3 (185/272) | step 730 | avg_nll=22.25 avg_ppl=21.63 speed=9525.32 words/sec time_elapsed=21.79 sec\n",
            "epoch 3 (195/272) | step 740 | avg_nll=21.58 avg_ppl=20.37 speed=9529.27 words/sec time_elapsed=22.03 sec\n",
            "epoch 3 (205/272) | step 750 | avg_nll=22.38 avg_ppl=22.29 speed=10206.49 words/sec time_elapsed=22.26 sec\n",
            "epoch 3 (215/272) | step 760 | avg_nll=22.38 avg_ppl=21.78 speed=10067.75 words/sec time_elapsed=22.49 sec\n",
            "epoch 3 (225/272) | step 770 | avg_nll=21.31 avg_ppl=19.01 speed=9527.49 words/sec time_elapsed=22.73 sec\n",
            "epoch 3 (235/272) | step 780 | avg_nll=22.48 avg_ppl=22.55 speed=9492.79 words/sec time_elapsed=22.98 sec\n",
            "epoch 3 (245/272) | step 790 | avg_nll=21.36 avg_ppl=20.00 speed=9854.14 words/sec time_elapsed=23.21 sec\n",
            "epoch 3 (255/272) | step 800 | avg_nll=21.34 avg_ppl=19.78 speed=10341.85 words/sec time_elapsed=23.43 sec\n",
            "Begin validation ...\n",
            "validation: step 800 | dev_ppl=20.16325569152832\n",
            "epoch 3 step 800: save currently the best model to 'model.pt'\n",
            "epoch 3 (265/272) | step 810 | avg_nll=23.12 avg_ppl=22.97 speed=5746.40 words/sec time_elapsed=23.84 sec\n",
            "epoch 4 (3/272) | step 820 | avg_nll=20.99 avg_ppl=18.50 speed=10212.50 words/sec time_elapsed=24.06 sec\n",
            "epoch 4 (13/272) | step 830 | avg_nll=20.97 avg_ppl=18.55 speed=10046.83 words/sec time_elapsed=24.29 sec\n",
            "epoch 4 (23/272) | step 840 | avg_nll=21.42 avg_ppl=18.83 speed=10269.49 words/sec time_elapsed=24.52 sec\n",
            "epoch 4 (33/272) | step 850 | avg_nll=21.51 avg_ppl=19.63 speed=10114.59 words/sec time_elapsed=24.75 sec\n",
            "epoch 4 (43/272) | step 860 | avg_nll=21.11 avg_ppl=18.61 speed=9633.93 words/sec time_elapsed=24.99 sec\n",
            "epoch 4 (53/272) | step 870 | avg_nll=20.90 avg_ppl=18.25 speed=10001.68 words/sec time_elapsed=25.22 sec\n",
            "epoch 4 (63/272) | step 880 | avg_nll=21.96 avg_ppl=20.18 speed=9899.76 words/sec time_elapsed=25.46 sec\n",
            "epoch 4 (73/272) | step 890 | avg_nll=21.38 avg_ppl=18.77 speed=9612.30 words/sec time_elapsed=25.70 sec\n",
            "epoch 4 (83/272) | step 900 | avg_nll=21.69 avg_ppl=19.56 speed=9420.60 words/sec time_elapsed=25.95 sec\n",
            "Begin validation ...\n",
            "validation: step 900 | dev_ppl=18.89995765686035\n",
            "epoch 4 step 900: save currently the best model to 'model.pt'\n",
            "epoch 4 (93/272) | step 910 | avg_nll=21.06 avg_ppl=18.11 speed=5843.23 words/sec time_elapsed=26.34 sec\n",
            "epoch 4 (103/272) | step 920 | avg_nll=21.33 avg_ppl=19.49 speed=10132.70 words/sec time_elapsed=26.57 sec\n",
            "epoch 4 (113/272) | step 930 | avg_nll=20.96 avg_ppl=18.56 speed=9748.91 words/sec time_elapsed=26.81 sec\n",
            "epoch 4 (123/272) | step 940 | avg_nll=21.23 avg_ppl=18.36 speed=9711.67 words/sec time_elapsed=27.05 sec\n",
            "epoch 4 (133/272) | step 950 | avg_nll=21.38 avg_ppl=19.03 speed=10134.93 words/sec time_elapsed=27.28 sec\n",
            "epoch 4 (143/272) | step 960 | avg_nll=21.49 avg_ppl=18.78 speed=10472.14 words/sec time_elapsed=27.50 sec\n",
            "epoch 4 (153/272) | step 970 | avg_nll=21.27 avg_ppl=18.80 speed=10053.68 words/sec time_elapsed=27.73 sec\n",
            "epoch 4 (163/272) | step 980 | avg_nll=22.50 avg_ppl=21.31 speed=9891.32 words/sec time_elapsed=27.97 sec\n",
            "epoch 4 (173/272) | step 990 | avg_nll=20.34 avg_ppl=17.34 speed=10134.50 words/sec time_elapsed=28.19 sec\n",
            "epoch 4 (183/272) | step 1000 | avg_nll=20.95 avg_ppl=18.07 speed=10289.27 words/sec time_elapsed=28.42 sec\n",
            "Begin validation ...\n",
            "validation: step 1000 | dev_ppl=18.41551971435547\n",
            "epoch 4 step 1000: save currently the best model to 'model.pt'\n",
            "epoch 4 (193/272) | step 1010 | avg_nll=20.80 avg_ppl=17.54 speed=5782.99 words/sec time_elapsed=28.82 sec\n",
            "epoch 4 (203/272) | step 1020 | avg_nll=20.76 avg_ppl=17.53 speed=9801.83 words/sec time_elapsed=29.06 sec\n",
            "epoch 4 (213/272) | step 1030 | avg_nll=20.55 avg_ppl=17.27 speed=6605.39 words/sec time_elapsed=29.41 sec\n",
            "epoch 4 (223/272) | step 1040 | avg_nll=20.21 avg_ppl=16.90 speed=7029.06 words/sec time_elapsed=29.73 sec\n",
            "epoch 4 (233/272) | step 1050 | avg_nll=21.66 avg_ppl=19.74 speed=7138.29 words/sec time_elapsed=30.06 sec\n",
            "epoch 4 (243/272) | step 1060 | avg_nll=20.50 avg_ppl=17.07 speed=7717.62 words/sec time_elapsed=30.36 sec\n",
            "epoch 4 (253/272) | step 1070 | avg_nll=20.24 avg_ppl=16.22 speed=6653.90 words/sec time_elapsed=30.71 sec\n",
            "epoch 4 (263/272) | step 1080 | avg_nll=19.93 avg_ppl=16.48 speed=5995.48 words/sec time_elapsed=31.09 sec\n",
            "epoch 5 (1/272) | step 1090 | avg_nll=20.91 avg_ppl=18.03 speed=6426.42 words/sec time_elapsed=31.45 sec\n",
            "epoch 5 (11/272) | step 1100 | avg_nll=20.91 avg_ppl=17.59 speed=6646.33 words/sec time_elapsed=31.81 sec\n",
            "Begin validation ...\n",
            "validation: step 1100 | dev_ppl=16.753070831298828\n",
            "epoch 5 step 1100: save currently the best model to 'model.pt'\n",
            "epoch 5 (21/272) | step 1110 | avg_nll=18.36 avg_ppl=13.72 speed=5442.67 words/sec time_elapsed=32.22 sec\n",
            "epoch 5 (31/272) | step 1120 | avg_nll=19.75 avg_ppl=15.33 speed=9946.27 words/sec time_elapsed=32.45 sec\n",
            "epoch 5 (41/272) | step 1130 | avg_nll=20.48 avg_ppl=16.09 speed=9782.48 words/sec time_elapsed=32.69 sec\n",
            "epoch 5 (51/272) | step 1140 | avg_nll=20.31 avg_ppl=15.95 speed=10088.73 words/sec time_elapsed=32.92 sec\n",
            "epoch 5 (61/272) | step 1150 | avg_nll=20.39 avg_ppl=16.27 speed=9756.93 words/sec time_elapsed=33.16 sec\n",
            "epoch 5 (71/272) | step 1160 | avg_nll=20.02 avg_ppl=16.30 speed=9707.27 words/sec time_elapsed=33.40 sec\n",
            "epoch 5 (81/272) | step 1170 | avg_nll=20.47 avg_ppl=16.72 speed=9574.04 words/sec time_elapsed=33.64 sec\n",
            "epoch 5 (91/272) | step 1180 | avg_nll=20.46 avg_ppl=16.47 speed=9939.76 words/sec time_elapsed=33.88 sec\n",
            "epoch 5 (101/272) | step 1190 | avg_nll=20.79 avg_ppl=16.73 speed=9320.43 words/sec time_elapsed=34.13 sec\n",
            "epoch 5 (111/272) | step 1200 | avg_nll=20.05 avg_ppl=15.92 speed=9931.60 words/sec time_elapsed=34.37 sec\n",
            "Begin validation ...\n",
            "validation: step 1200 | dev_ppl=15.855231285095215\n",
            "epoch 5 step 1200: save currently the best model to 'model.pt'\n",
            "epoch 5 (121/272) | step 1210 | avg_nll=20.21 avg_ppl=15.99 speed=5438.55 words/sec time_elapsed=34.79 sec\n",
            "epoch 5 (131/272) | step 1220 | avg_nll=19.53 avg_ppl=15.13 speed=9809.12 words/sec time_elapsed=35.03 sec\n",
            "epoch 5 (141/272) | step 1230 | avg_nll=19.89 avg_ppl=15.96 speed=9305.88 words/sec time_elapsed=35.28 sec\n",
            "epoch 5 (151/272) | step 1240 | avg_nll=20.00 avg_ppl=15.94 speed=10157.57 words/sec time_elapsed=35.50 sec\n",
            "epoch 5 (161/272) | step 1250 | avg_nll=20.15 avg_ppl=15.93 speed=9797.22 words/sec time_elapsed=35.74 sec\n",
            "epoch 5 (171/272) | step 1260 | avg_nll=18.95 avg_ppl=13.63 speed=10156.24 words/sec time_elapsed=35.97 sec\n",
            "epoch 5 (181/272) | step 1270 | avg_nll=18.79 avg_ppl=14.12 speed=8914.59 words/sec time_elapsed=36.23 sec\n",
            "epoch 5 (191/272) | step 1280 | avg_nll=19.40 avg_ppl=15.32 speed=9328.85 words/sec time_elapsed=36.47 sec\n",
            "epoch 5 (201/272) | step 1290 | avg_nll=19.51 avg_ppl=15.45 speed=9648.21 words/sec time_elapsed=36.71 sec\n",
            "epoch 5 (211/272) | step 1300 | avg_nll=20.27 avg_ppl=15.78 speed=9917.95 words/sec time_elapsed=36.94 sec\n",
            "Begin validation ...\n",
            "validation: step 1300 | dev_ppl=15.17087173461914\n",
            "epoch 5 step 1300: save currently the best model to 'model.pt'\n",
            "epoch 5 (221/272) | step 1310 | avg_nll=19.41 avg_ppl=14.55 speed=5467.07 words/sec time_elapsed=37.37 sec\n",
            "epoch 5 (231/272) | step 1320 | avg_nll=18.46 avg_ppl=13.23 speed=10015.62 words/sec time_elapsed=37.60 sec\n",
            "epoch 5 (241/272) | step 1330 | avg_nll=20.49 avg_ppl=15.94 speed=10050.10 words/sec time_elapsed=37.83 sec\n",
            "epoch 5 (251/272) | step 1340 | avg_nll=19.12 avg_ppl=14.21 speed=9855.62 words/sec time_elapsed=38.07 sec\n",
            "epoch 5 (261/272) | step 1350 | avg_nll=18.43 avg_ppl=13.51 speed=9269.33 words/sec time_elapsed=38.31 sec\n",
            "epoch 5 (271/272) | step 1360 | avg_nll=20.23 avg_ppl=15.55 speed=10252.52 words/sec time_elapsed=38.54 sec\n",
            "epoch 6 (9/272) | step 1370 | avg_nll=19.17 avg_ppl=14.02 speed=9785.82 words/sec time_elapsed=38.78 sec\n",
            "epoch 6 (19/272) | step 1380 | avg_nll=18.32 avg_ppl=12.87 speed=9479.43 words/sec time_elapsed=39.02 sec\n",
            "epoch 6 (29/272) | step 1390 | avg_nll=19.21 avg_ppl=13.69 speed=9612.25 words/sec time_elapsed=39.26 sec\n",
            "epoch 6 (39/272) | step 1400 | avg_nll=19.24 avg_ppl=13.86 speed=10308.63 words/sec time_elapsed=39.49 sec\n",
            "Begin validation ...\n",
            "validation: step 1400 | dev_ppl=14.743911743164062\n",
            "epoch 6 step 1400: save currently the best model to 'model.pt'\n",
            "epoch 6 (49/272) | step 1410 | avg_nll=19.04 avg_ppl=13.92 speed=5613.57 words/sec time_elapsed=39.90 sec\n",
            "epoch 6 (59/272) | step 1420 | avg_nll=18.00 avg_ppl=12.67 speed=9929.28 words/sec time_elapsed=40.13 sec\n",
            "epoch 6 (69/272) | step 1430 | avg_nll=18.82 avg_ppl=13.29 speed=9277.26 words/sec time_elapsed=40.38 sec\n",
            "epoch 6 (79/272) | step 1440 | avg_nll=20.14 avg_ppl=15.11 speed=9903.41 words/sec time_elapsed=40.62 sec\n",
            "epoch 6 (89/272) | step 1450 | avg_nll=18.83 avg_ppl=13.26 speed=9229.87 words/sec time_elapsed=40.88 sec\n",
            "epoch 6 (99/272) | step 1460 | avg_nll=18.50 avg_ppl=13.26 speed=9466.90 words/sec time_elapsed=41.12 sec\n",
            "epoch 6 (109/272) | step 1470 | avg_nll=18.82 avg_ppl=13.72 speed=9682.36 words/sec time_elapsed=41.36 sec\n",
            "epoch 6 (119/272) | step 1480 | avg_nll=18.96 avg_ppl=13.60 speed=10218.98 words/sec time_elapsed=41.58 sec\n",
            "epoch 6 (129/272) | step 1490 | avg_nll=18.19 avg_ppl=12.65 speed=8001.21 words/sec time_elapsed=41.87 sec\n",
            "epoch 6 (139/272) | step 1500 | avg_nll=18.36 avg_ppl=12.92 speed=6810.27 words/sec time_elapsed=42.21 sec\n",
            "Begin validation ...\n",
            "validation: step 1500 | dev_ppl=14.128103256225586\n",
            "epoch 6 step 1500: save currently the best model to 'model.pt'\n",
            "epoch 6 (149/272) | step 1510 | avg_nll=19.31 avg_ppl=13.86 speed=3935.29 words/sec time_elapsed=42.81 sec\n",
            "epoch 6 (159/272) | step 1520 | avg_nll=19.91 avg_ppl=15.61 speed=7043.40 words/sec time_elapsed=43.14 sec\n",
            "epoch 6 (169/272) | step 1530 | avg_nll=19.16 avg_ppl=14.06 speed=6646.52 words/sec time_elapsed=43.49 sec\n",
            "epoch 6 (179/272) | step 1540 | avg_nll=18.98 avg_ppl=13.82 speed=6134.38 words/sec time_elapsed=43.86 sec\n",
            "epoch 6 (189/272) | step 1550 | avg_nll=18.75 avg_ppl=13.20 speed=6738.00 words/sec time_elapsed=44.21 sec\n",
            "epoch 6 (199/272) | step 1560 | avg_nll=19.34 avg_ppl=14.06 speed=6715.26 words/sec time_elapsed=44.56 sec\n",
            "epoch 6 (209/272) | step 1570 | avg_nll=18.94 avg_ppl=13.72 speed=9923.31 words/sec time_elapsed=44.79 sec\n",
            "epoch 6 (219/272) | step 1580 | avg_nll=17.91 avg_ppl=11.84 speed=10189.89 words/sec time_elapsed=45.02 sec\n",
            "epoch 6 (229/272) | step 1590 | avg_nll=18.04 avg_ppl=12.20 speed=9748.65 words/sec time_elapsed=45.26 sec\n",
            "epoch 6 (239/272) | step 1600 | avg_nll=19.23 avg_ppl=13.36 speed=10136.81 words/sec time_elapsed=45.49 sec\n",
            "Begin validation ...\n",
            "validation: step 1600 | dev_ppl=13.512687683105469\n",
            "epoch 6 step 1600: save currently the best model to 'model.pt'\n",
            "epoch 6 (249/272) | step 1610 | avg_nll=17.15 avg_ppl=11.23 speed=5429.22 words/sec time_elapsed=45.91 sec\n",
            "epoch 6 (259/272) | step 1620 | avg_nll=17.79 avg_ppl=12.11 speed=9683.60 words/sec time_elapsed=46.14 sec\n",
            "epoch 6 (269/272) | step 1630 | avg_nll=19.09 avg_ppl=14.14 speed=10270.06 words/sec time_elapsed=46.37 sec\n",
            "epoch 7 (7/272) | step 1640 | avg_nll=18.00 avg_ppl=12.28 speed=9365.57 words/sec time_elapsed=46.61 sec\n",
            "epoch 7 (17/272) | step 1650 | avg_nll=18.95 avg_ppl=13.26 speed=9504.31 words/sec time_elapsed=46.86 sec\n",
            "epoch 7 (27/272) | step 1660 | avg_nll=18.83 avg_ppl=13.59 speed=9333.27 words/sec time_elapsed=47.11 sec\n",
            "epoch 7 (37/272) | step 1670 | avg_nll=18.67 avg_ppl=12.71 speed=9482.72 words/sec time_elapsed=47.36 sec\n",
            "epoch 7 (47/272) | step 1680 | avg_nll=17.39 avg_ppl=10.97 speed=9721.50 words/sec time_elapsed=47.60 sec\n",
            "epoch 7 (57/272) | step 1690 | avg_nll=18.35 avg_ppl=12.67 speed=9808.39 words/sec time_elapsed=47.83 sec\n",
            "epoch 7 (67/272) | step 1700 | avg_nll=17.70 avg_ppl=11.34 speed=10056.01 words/sec time_elapsed=48.06 sec\n",
            "Begin validation ...\n",
            "validation: step 1700 | dev_ppl=13.220703125\n",
            "epoch 7 step 1700: save currently the best model to 'model.pt'\n",
            "epoch 7 (77/272) | step 1710 | avg_nll=17.98 avg_ppl=12.16 speed=5682.05 words/sec time_elapsed=48.47 sec\n",
            "epoch 7 (87/272) | step 1720 | avg_nll=16.57 avg_ppl=10.28 speed=9814.91 words/sec time_elapsed=48.70 sec\n",
            "epoch 7 (97/272) | step 1730 | avg_nll=18.16 avg_ppl=12.87 speed=9348.60 words/sec time_elapsed=48.94 sec\n",
            "epoch 7 (107/272) | step 1740 | avg_nll=18.68 avg_ppl=12.78 speed=10263.43 words/sec time_elapsed=49.17 sec\n",
            "epoch 7 (117/272) | step 1750 | avg_nll=17.33 avg_ppl=10.85 speed=9951.55 words/sec time_elapsed=49.41 sec\n",
            "epoch 7 (127/272) | step 1760 | avg_nll=18.23 avg_ppl=12.34 speed=8761.13 words/sec time_elapsed=49.67 sec\n",
            "epoch 7 (137/272) | step 1770 | avg_nll=17.87 avg_ppl=11.87 speed=9708.77 words/sec time_elapsed=49.91 sec\n",
            "epoch 7 (147/272) | step 1780 | avg_nll=17.97 avg_ppl=11.68 speed=10458.02 words/sec time_elapsed=50.13 sec\n",
            "epoch 7 (157/272) | step 1790 | avg_nll=17.97 avg_ppl=12.10 speed=10296.42 words/sec time_elapsed=50.36 sec\n",
            "epoch 7 (167/272) | step 1800 | avg_nll=16.26 avg_ppl=10.10 speed=8855.07 words/sec time_elapsed=50.61 sec\n",
            "Begin validation ...\n",
            "validation: step 1800 | dev_ppl=12.665186882019043\n",
            "epoch 7 step 1800: save currently the best model to 'model.pt'\n",
            "epoch 7 (177/272) | step 1810 | avg_nll=18.38 avg_ppl=12.77 speed=5637.65 words/sec time_elapsed=51.02 sec\n",
            "epoch 7 (187/272) | step 1820 | avg_nll=17.66 avg_ppl=11.58 speed=9806.41 words/sec time_elapsed=51.26 sec\n",
            "epoch 7 (197/272) | step 1830 | avg_nll=19.21 avg_ppl=13.47 speed=10507.32 words/sec time_elapsed=51.48 sec\n",
            "epoch 7 (207/272) | step 1840 | avg_nll=17.66 avg_ppl=11.40 speed=9679.41 words/sec time_elapsed=51.72 sec\n",
            "epoch 7 (217/272) | step 1850 | avg_nll=18.14 avg_ppl=11.78 speed=10127.24 words/sec time_elapsed=51.95 sec\n",
            "epoch 7 (227/272) | step 1860 | avg_nll=17.83 avg_ppl=11.46 speed=10440.21 words/sec time_elapsed=52.18 sec\n",
            "epoch 7 (237/272) | step 1870 | avg_nll=18.18 avg_ppl=11.89 speed=10455.96 words/sec time_elapsed=52.40 sec\n",
            "epoch 7 (247/272) | step 1880 | avg_nll=17.58 avg_ppl=11.70 speed=9720.42 words/sec time_elapsed=52.64 sec\n",
            "epoch 7 (257/272) | step 1890 | avg_nll=17.96 avg_ppl=11.68 speed=9951.62 words/sec time_elapsed=52.87 sec\n",
            "epoch 7 (267/272) | step 1900 | avg_nll=16.67 avg_ppl=10.28 speed=9941.39 words/sec time_elapsed=53.10 sec\n",
            "Begin validation ...\n",
            "validation: step 1900 | dev_ppl=12.236180305480957\n",
            "epoch 7 step 1900: save currently the best model to 'model.pt'\n",
            "epoch 8 (5/272) | step 1910 | avg_nll=16.73 avg_ppl=10.56 speed=5761.51 words/sec time_elapsed=53.50 sec\n",
            "epoch 8 (15/272) | step 1920 | avg_nll=16.92 avg_ppl=10.33 speed=9611.68 words/sec time_elapsed=53.74 sec\n",
            "epoch 8 (25/272) | step 1930 | avg_nll=16.87 avg_ppl=10.25 speed=9703.39 words/sec time_elapsed=53.98 sec\n",
            "epoch 8 (35/272) | step 1940 | avg_nll=17.48 avg_ppl=11.22 speed=9429.82 words/sec time_elapsed=54.22 sec\n",
            "epoch 8 (45/272) | step 1950 | avg_nll=17.13 avg_ppl=10.48 speed=10394.33 words/sec time_elapsed=54.45 sec\n",
            "epoch 8 (55/272) | step 1960 | avg_nll=16.76 avg_ppl=10.59 speed=6526.10 words/sec time_elapsed=54.80 sec\n",
            "epoch 8 (65/272) | step 1970 | avg_nll=16.31 avg_ppl=9.65 speed=7155.56 words/sec time_elapsed=55.12 sec\n",
            "epoch 8 (75/272) | step 1980 | avg_nll=17.11 avg_ppl=10.83 speed=7286.40 words/sec time_elapsed=55.44 sec\n",
            "epoch 8 (85/272) | step 1990 | avg_nll=17.44 avg_ppl=10.91 speed=7401.15 words/sec time_elapsed=55.75 sec\n",
            "epoch 8 (95/272) | step 2000 | avg_nll=17.00 avg_ppl=10.68 speed=6553.45 words/sec time_elapsed=56.10 sec\n",
            "Begin validation ...\n",
            "validation: step 2000 | dev_ppl=12.019328117370605\n",
            "epoch 8 step 2000: save currently the best model to 'model.pt'\n",
            "epoch 8 (105/272) | step 2010 | avg_nll=16.74 avg_ppl=10.19 speed=3625.74 words/sec time_elapsed=56.74 sec\n",
            "epoch 8 (115/272) | step 2020 | avg_nll=17.41 avg_ppl=10.98 speed=6502.10 words/sec time_elapsed=57.10 sec\n",
            "epoch 8 (125/272) | step 2030 | avg_nll=17.35 avg_ppl=10.49 speed=7236.53 words/sec time_elapsed=57.43 sec\n",
            "epoch 8 (135/272) | step 2040 | avg_nll=17.79 avg_ppl=11.67 speed=10034.42 words/sec time_elapsed=57.66 sec\n",
            "epoch 8 (145/272) | step 2050 | avg_nll=17.37 avg_ppl=11.05 speed=9370.87 words/sec time_elapsed=57.90 sec\n",
            "epoch 8 (155/272) | step 2060 | avg_nll=17.66 avg_ppl=10.69 speed=10212.57 words/sec time_elapsed=58.14 sec\n",
            "epoch 8 (165/272) | step 2070 | avg_nll=16.11 avg_ppl=9.40 speed=10335.86 words/sec time_elapsed=58.36 sec\n",
            "epoch 8 (175/272) | step 2080 | avg_nll=17.74 avg_ppl=11.10 speed=10454.50 words/sec time_elapsed=58.59 sec\n",
            "epoch 8 (185/272) | step 2090 | avg_nll=17.75 avg_ppl=11.57 speed=9845.38 words/sec time_elapsed=58.82 sec\n",
            "epoch 8 (195/272) | step 2100 | avg_nll=16.94 avg_ppl=10.71 speed=9598.34 words/sec time_elapsed=59.06 sec\n",
            "Begin validation ...\n",
            "validation: step 2100 | dev_ppl=11.907407760620117\n",
            "epoch 8 step 2100: save currently the best model to 'model.pt'\n",
            "epoch 8 (205/272) | step 2110 | avg_nll=17.98 avg_ppl=11.83 speed=5738.66 words/sec time_elapsed=59.47 sec\n",
            "epoch 8 (215/272) | step 2120 | avg_nll=16.99 avg_ppl=10.58 speed=9730.22 words/sec time_elapsed=59.70 sec\n",
            "epoch 8 (225/272) | step 2130 | avg_nll=16.82 avg_ppl=10.33 speed=9382.66 words/sec time_elapsed=59.95 sec\n",
            "epoch 8 (235/272) | step 2140 | avg_nll=16.15 avg_ppl=9.86 speed=9921.36 words/sec time_elapsed=60.18 sec\n",
            "epoch 8 (245/272) | step 2150 | avg_nll=16.66 avg_ppl=10.01 speed=10190.34 words/sec time_elapsed=60.40 sec\n",
            "epoch 8 (255/272) | step 2160 | avg_nll=17.57 avg_ppl=11.10 speed=10635.08 words/sec time_elapsed=60.62 sec\n",
            "epoch 8 (265/272) | step 2170 | avg_nll=17.62 avg_ppl=11.30 speed=8956.00 words/sec time_elapsed=60.88 sec\n",
            "epoch 9 (3/272) | step 2180 | avg_nll=16.68 avg_ppl=10.08 speed=10119.30 words/sec time_elapsed=61.11 sec\n",
            "epoch 9 (13/272) | step 2190 | avg_nll=16.43 avg_ppl=9.78 speed=9266.25 words/sec time_elapsed=61.36 sec\n",
            "epoch 9 (23/272) | step 2200 | avg_nll=16.06 avg_ppl=9.24 speed=10082.90 words/sec time_elapsed=61.59 sec\n",
            "Begin validation ...\n",
            "validation: step 2200 | dev_ppl=11.348109245300293\n",
            "epoch 9 step 2200: save currently the best model to 'model.pt'\n",
            "epoch 9 (33/272) | step 2210 | avg_nll=16.31 avg_ppl=9.79 speed=5531.02 words/sec time_elapsed=62.00 sec\n",
            "epoch 9 (43/272) | step 2220 | avg_nll=16.89 avg_ppl=10.11 speed=10267.63 words/sec time_elapsed=62.23 sec\n",
            "epoch 9 (53/272) | step 2230 | avg_nll=16.93 avg_ppl=10.41 speed=10596.74 words/sec time_elapsed=62.45 sec\n",
            "epoch 9 (63/272) | step 2240 | avg_nll=16.82 avg_ppl=10.00 speed=10523.90 words/sec time_elapsed=62.67 sec\n",
            "epoch 9 (73/272) | step 2250 | avg_nll=16.68 avg_ppl=9.73 speed=9574.48 words/sec time_elapsed=62.92 sec\n",
            "epoch 9 (83/272) | step 2260 | avg_nll=16.42 avg_ppl=9.60 speed=10009.28 words/sec time_elapsed=63.15 sec\n",
            "epoch 9 (93/272) | step 2270 | avg_nll=16.96 avg_ppl=10.38 speed=10167.95 words/sec time_elapsed=63.38 sec\n",
            "epoch 9 (103/272) | step 2280 | avg_nll=15.70 avg_ppl=8.94 speed=9931.56 words/sec time_elapsed=63.61 sec\n",
            "epoch 9 (113/272) | step 2290 | avg_nll=16.23 avg_ppl=9.82 speed=9713.24 words/sec time_elapsed=63.84 sec\n",
            "epoch 9 (123/272) | step 2300 | avg_nll=16.88 avg_ppl=9.89 speed=9810.31 words/sec time_elapsed=64.08 sec\n",
            "Begin validation ...\n",
            "validation: step 2300 | dev_ppl=11.144515991210938\n",
            "epoch 9 step 2300: save currently the best model to 'model.pt'\n",
            "epoch 9 (133/272) | step 2310 | avg_nll=16.32 avg_ppl=9.79 speed=5496.69 words/sec time_elapsed=64.50 sec\n",
            "epoch 9 (143/272) | step 2320 | avg_nll=16.02 avg_ppl=9.24 speed=9903.85 words/sec time_elapsed=64.73 sec\n",
            "epoch 9 (153/272) | step 2330 | avg_nll=17.14 avg_ppl=10.52 speed=9513.64 words/sec time_elapsed=64.98 sec\n",
            "epoch 9 (163/272) | step 2340 | avg_nll=16.47 avg_ppl=9.85 speed=10135.53 words/sec time_elapsed=65.20 sec\n",
            "epoch 9 (173/272) | step 2350 | avg_nll=17.04 avg_ppl=10.31 speed=10352.09 words/sec time_elapsed=65.43 sec\n",
            "epoch 9 (183/272) | step 2360 | avg_nll=16.44 avg_ppl=10.01 speed=10338.64 words/sec time_elapsed=65.65 sec\n",
            "epoch 9 (193/272) | step 2370 | avg_nll=15.83 avg_ppl=8.85 speed=9617.48 words/sec time_elapsed=65.89 sec\n",
            "epoch 9 (203/272) | step 2380 | avg_nll=16.22 avg_ppl=9.33 speed=9466.50 words/sec time_elapsed=66.14 sec\n",
            "epoch 9 (213/272) | step 2390 | avg_nll=16.89 avg_ppl=10.37 speed=10377.03 words/sec time_elapsed=66.36 sec\n",
            "epoch 9 (223/272) | step 2400 | avg_nll=16.45 avg_ppl=9.15 speed=10858.01 words/sec time_elapsed=66.58 sec\n",
            "Begin validation ...\n",
            "validation: step 2400 | dev_ppl=10.881742477416992\n",
            "epoch 9 step 2400: save currently the best model to 'model.pt'\n",
            "epoch 9 (233/272) | step 2410 | avg_nll=17.13 avg_ppl=10.47 speed=5658.67 words/sec time_elapsed=66.99 sec\n",
            "epoch 9 (243/272) | step 2420 | avg_nll=17.28 avg_ppl=10.77 speed=10325.53 words/sec time_elapsed=67.22 sec\n",
            "epoch 9 (253/272) | step 2430 | avg_nll=15.18 avg_ppl=8.40 speed=8289.41 words/sec time_elapsed=67.49 sec\n",
            "epoch 9 (263/272) | step 2440 | avg_nll=15.93 avg_ppl=8.81 speed=7044.70 words/sec time_elapsed=67.83 sec\n",
            "epoch 10 (1/272) | step 2450 | avg_nll=16.39 avg_ppl=9.88 speed=7053.70 words/sec time_elapsed=68.15 sec\n",
            "epoch 10 (11/272) | step 2460 | avg_nll=15.90 avg_ppl=9.02 speed=7557.48 words/sec time_elapsed=68.46 sec\n",
            "epoch 10 (21/272) | step 2470 | avg_nll=14.92 avg_ppl=8.08 speed=6832.30 words/sec time_elapsed=68.79 sec\n",
            "epoch 10 (31/272) | step 2480 | avg_nll=15.40 avg_ppl=8.49 speed=6460.29 words/sec time_elapsed=69.15 sec\n",
            "epoch 10 (41/272) | step 2490 | avg_nll=15.46 avg_ppl=8.57 speed=6302.54 words/sec time_elapsed=69.52 sec\n",
            "epoch 10 (51/272) | step 2500 | avg_nll=16.06 avg_ppl=8.98 speed=6468.83 words/sec time_elapsed=69.88 sec\n",
            "Begin validation ...\n",
            "validation: step 2500 | dev_ppl=10.997252464294434\n",
            "epoch 10 (61/272) | step 2510 | avg_nll=16.06 avg_ppl=9.10 speed=5729.66 words/sec time_elapsed=70.29 sec\n",
            "epoch 10 (71/272) | step 2520 | avg_nll=15.98 avg_ppl=9.34 speed=9897.70 words/sec time_elapsed=70.52 sec\n",
            "epoch 10 (81/272) | step 2530 | avg_nll=15.38 avg_ppl=8.40 speed=9274.13 words/sec time_elapsed=70.77 sec\n",
            "epoch 10 (91/272) | step 2540 | avg_nll=14.97 avg_ppl=8.44 speed=9665.10 words/sec time_elapsed=71.00 sec\n",
            "epoch 10 (101/272) | step 2550 | avg_nll=16.79 avg_ppl=10.00 speed=9587.79 words/sec time_elapsed=71.24 sec\n",
            "epoch 10 (111/272) | step 2560 | avg_nll=14.91 avg_ppl=7.85 speed=9879.31 words/sec time_elapsed=71.48 sec\n",
            "epoch 10 (121/272) | step 2570 | avg_nll=17.00 avg_ppl=10.06 speed=9935.78 words/sec time_elapsed=71.71 sec\n",
            "epoch 10 (131/272) | step 2580 | avg_nll=14.72 avg_ppl=7.71 speed=9864.43 words/sec time_elapsed=71.95 sec\n",
            "epoch 10 (141/272) | step 2590 | avg_nll=16.83 avg_ppl=9.81 speed=9648.43 words/sec time_elapsed=72.19 sec\n",
            "epoch 10 (151/272) | step 2600 | avg_nll=15.58 avg_ppl=8.78 speed=9749.80 words/sec time_elapsed=72.43 sec\n",
            "Begin validation ...\n",
            "validation: step 2600 | dev_ppl=10.566190719604492\n",
            "epoch 10 step 2600: save currently the best model to 'model.pt'\n",
            "epoch 10 (161/272) | step 2610 | avg_nll=15.25 avg_ppl=8.04 speed=5489.55 words/sec time_elapsed=72.86 sec\n",
            "epoch 10 (171/272) | step 2620 | avg_nll=16.96 avg_ppl=10.07 speed=10166.25 words/sec time_elapsed=73.09 sec\n",
            "epoch 10 (181/272) | step 2630 | avg_nll=16.65 avg_ppl=9.41 speed=9984.57 words/sec time_elapsed=73.32 sec\n",
            "epoch 10 (191/272) | step 2640 | avg_nll=15.21 avg_ppl=8.35 speed=10216.55 words/sec time_elapsed=73.55 sec\n",
            "epoch 10 (201/272) | step 2650 | avg_nll=14.97 avg_ppl=8.08 speed=10199.68 words/sec time_elapsed=73.77 sec\n",
            "epoch 10 (211/272) | step 2660 | avg_nll=16.09 avg_ppl=9.10 speed=10124.30 words/sec time_elapsed=74.00 sec\n",
            "epoch 10 (221/272) | step 2670 | avg_nll=14.83 avg_ppl=8.04 speed=9587.97 words/sec time_elapsed=74.24 sec\n",
            "epoch 10 (231/272) | step 2680 | avg_nll=15.27 avg_ppl=8.15 speed=10011.07 words/sec time_elapsed=74.48 sec\n",
            "epoch 10 (241/272) | step 2690 | avg_nll=17.22 avg_ppl=10.03 speed=10677.36 words/sec time_elapsed=74.70 sec\n",
            "epoch 10 (251/272) | step 2700 | avg_nll=16.02 avg_ppl=9.12 speed=9432.93 words/sec time_elapsed=74.94 sec\n",
            "Begin validation ...\n",
            "validation: step 2700 | dev_ppl=10.167399406433105\n",
            "epoch 10 step 2700: save currently the best model to 'model.pt'\n",
            "epoch 10 (261/272) | step 2710 | avg_nll=15.33 avg_ppl=8.67 speed=5513.12 words/sec time_elapsed=75.36 sec\n",
            "epoch 10 (271/272) | step 2720 | avg_nll=14.69 avg_ppl=7.86 speed=10033.43 words/sec time_elapsed=75.58 sec\n",
            "epoch 11 (9/272) | step 2730 | avg_nll=13.93 avg_ppl=7.18 speed=9773.69 words/sec time_elapsed=75.82 sec\n",
            "epoch 11 (19/272) | step 2740 | avg_nll=14.15 avg_ppl=7.16 speed=9503.16 words/sec time_elapsed=76.06 sec\n",
            "epoch 11 (29/272) | step 2750 | avg_nll=15.54 avg_ppl=8.65 speed=9835.96 words/sec time_elapsed=76.29 sec\n",
            "epoch 11 (39/272) | step 2760 | avg_nll=14.37 avg_ppl=7.38 speed=10366.74 words/sec time_elapsed=76.51 sec\n",
            "epoch 11 (49/272) | step 2770 | avg_nll=16.20 avg_ppl=8.95 speed=10391.56 words/sec time_elapsed=76.74 sec\n",
            "epoch 11 (59/272) | step 2780 | avg_nll=15.78 avg_ppl=8.76 speed=10438.80 words/sec time_elapsed=76.96 sec\n",
            "epoch 11 (69/272) | step 2790 | avg_nll=14.82 avg_ppl=8.04 speed=9440.97 words/sec time_elapsed=77.21 sec\n",
            "epoch 11 (79/272) | step 2800 | avg_nll=15.28 avg_ppl=7.98 speed=9680.25 words/sec time_elapsed=77.45 sec\n",
            "Begin validation ...\n",
            "validation: step 2800 | dev_ppl=10.241161346435547\n",
            "epoch 11 (89/272) | step 2810 | avg_nll=15.75 avg_ppl=8.73 speed=6411.33 words/sec time_elapsed=77.81 sec\n",
            "epoch 11 (99/272) | step 2820 | avg_nll=13.82 avg_ppl=7.09 speed=9619.17 words/sec time_elapsed=78.05 sec\n",
            "epoch 11 (109/272) | step 2830 | avg_nll=15.31 avg_ppl=8.24 speed=9664.19 words/sec time_elapsed=78.29 sec\n",
            "epoch 11 (119/272) | step 2840 | avg_nll=15.67 avg_ppl=8.47 speed=10299.60 words/sec time_elapsed=78.52 sec\n",
            "epoch 11 (129/272) | step 2850 | avg_nll=14.65 avg_ppl=7.55 speed=10223.24 words/sec time_elapsed=78.74 sec\n",
            "epoch 11 (139/272) | step 2860 | avg_nll=15.66 avg_ppl=8.42 speed=10388.59 words/sec time_elapsed=78.97 sec\n",
            "epoch 11 (149/272) | step 2870 | avg_nll=15.01 avg_ppl=8.05 speed=10237.15 words/sec time_elapsed=79.19 sec\n",
            "epoch 11 (159/272) | step 2880 | avg_nll=14.45 avg_ppl=7.29 speed=9712.19 words/sec time_elapsed=79.43 sec\n",
            "epoch 11 (169/272) | step 2890 | avg_nll=14.12 avg_ppl=7.38 speed=9926.21 words/sec time_elapsed=79.66 sec\n",
            "epoch 11 (179/272) | step 2900 | avg_nll=15.60 avg_ppl=8.34 speed=9508.79 words/sec time_elapsed=79.91 sec\n",
            "Begin validation ...\n",
            "validation: step 2900 | dev_ppl=9.80769157409668\n",
            "epoch 11 step 2900: save currently the best model to 'model.pt'\n",
            "epoch 11 (189/272) | step 2910 | avg_nll=15.71 avg_ppl=8.53 speed=3854.49 words/sec time_elapsed=80.52 sec\n",
            "epoch 11 (199/272) | step 2920 | avg_nll=15.04 avg_ppl=8.12 speed=6994.52 words/sec time_elapsed=80.85 sec\n",
            "epoch 11 (209/272) | step 2930 | avg_nll=16.56 avg_ppl=9.32 speed=7535.38 words/sec time_elapsed=81.16 sec\n",
            "epoch 11 (219/272) | step 2940 | avg_nll=15.47 avg_ppl=8.34 speed=7007.38 words/sec time_elapsed=81.50 sec\n",
            "epoch 11 (229/272) | step 2950 | avg_nll=15.84 avg_ppl=8.63 speed=6427.47 words/sec time_elapsed=81.86 sec\n",
            "epoch 11 (239/272) | step 2960 | avg_nll=14.49 avg_ppl=7.46 speed=6456.67 words/sec time_elapsed=82.22 sec\n",
            "epoch 11 (249/272) | step 2970 | avg_nll=14.77 avg_ppl=7.52 speed=6066.79 words/sec time_elapsed=82.61 sec\n",
            "epoch 11 (259/272) | step 2980 | avg_nll=13.92 avg_ppl=7.06 speed=8738.12 words/sec time_elapsed=82.87 sec\n",
            "epoch 11 (269/272) | step 2990 | avg_nll=14.77 avg_ppl=8.02 speed=9405.36 words/sec time_elapsed=83.11 sec\n",
            "epoch 12 (7/272) | step 3000 | avg_nll=14.72 avg_ppl=7.78 speed=9998.61 words/sec time_elapsed=83.34 sec\n",
            "Begin validation ...\n",
            "validation: step 3000 | dev_ppl=9.831883430480957\n",
            "epoch 12 (17/272) | step 3010 | avg_nll=12.94 avg_ppl=6.13 speed=6067.80 words/sec time_elapsed=83.72 sec\n",
            "epoch 12 (27/272) | step 3020 | avg_nll=13.61 avg_ppl=6.85 speed=9655.97 words/sec time_elapsed=83.95 sec\n",
            "epoch 12 (37/272) | step 3030 | avg_nll=14.30 avg_ppl=7.50 speed=9449.92 words/sec time_elapsed=84.19 sec\n",
            "epoch 12 (47/272) | step 3040 | avg_nll=14.01 avg_ppl=7.02 speed=8868.88 words/sec time_elapsed=84.45 sec\n",
            "epoch 12 (57/272) | step 3050 | avg_nll=13.85 avg_ppl=6.96 speed=9594.03 words/sec time_elapsed=84.69 sec\n",
            "epoch 12 (67/272) | step 3060 | avg_nll=14.99 avg_ppl=7.75 speed=9725.17 words/sec time_elapsed=84.93 sec\n",
            "epoch 12 (77/272) | step 3070 | avg_nll=15.24 avg_ppl=7.99 speed=9377.91 words/sec time_elapsed=85.18 sec\n",
            "epoch 12 (87/272) | step 3080 | avg_nll=14.32 avg_ppl=7.30 speed=9951.89 words/sec time_elapsed=85.41 sec\n",
            "epoch 12 (97/272) | step 3090 | avg_nll=15.07 avg_ppl=7.71 speed=9776.20 words/sec time_elapsed=85.65 sec\n",
            "epoch 12 (107/272) | step 3100 | avg_nll=14.11 avg_ppl=7.25 speed=9921.32 words/sec time_elapsed=85.88 sec\n",
            "Begin validation ...\n",
            "validation: step 3100 | dev_ppl=9.605009078979492\n",
            "epoch 12 step 3100: save currently the best model to 'model.pt'\n",
            "epoch 12 (117/272) | step 3110 | avg_nll=15.11 avg_ppl=8.03 speed=5787.89 words/sec time_elapsed=86.29 sec\n",
            "epoch 12 (127/272) | step 3120 | avg_nll=14.22 avg_ppl=7.13 speed=9800.75 words/sec time_elapsed=86.52 sec\n",
            "epoch 12 (137/272) | step 3130 | avg_nll=13.29 avg_ppl=6.47 speed=9980.10 words/sec time_elapsed=86.75 sec\n",
            "epoch 12 (147/272) | step 3140 | avg_nll=14.49 avg_ppl=7.28 speed=10142.53 words/sec time_elapsed=86.98 sec\n",
            "epoch 12 (157/272) | step 3150 | avg_nll=14.96 avg_ppl=7.76 speed=10114.47 words/sec time_elapsed=87.21 sec\n",
            "epoch 12 (167/272) | step 3160 | avg_nll=15.07 avg_ppl=7.99 speed=10333.74 words/sec time_elapsed=87.44 sec\n",
            "epoch 12 (177/272) | step 3170 | avg_nll=14.58 avg_ppl=7.41 speed=10108.84 words/sec time_elapsed=87.67 sec\n",
            "epoch 12 (187/272) | step 3180 | avg_nll=14.03 avg_ppl=6.92 speed=9919.43 words/sec time_elapsed=87.90 sec\n",
            "epoch 12 (197/272) | step 3190 | avg_nll=14.60 avg_ppl=7.50 speed=10143.56 words/sec time_elapsed=88.13 sec\n",
            "epoch 12 (207/272) | step 3200 | avg_nll=14.30 avg_ppl=7.02 speed=10454.46 words/sec time_elapsed=88.35 sec\n",
            "Begin validation ...\n",
            "validation: step 3200 | dev_ppl=9.388893127441406\n",
            "epoch 12 step 3200: save currently the best model to 'model.pt'\n",
            "epoch 12 (217/272) | step 3210 | avg_nll=13.50 avg_ppl=6.46 speed=5436.59 words/sec time_elapsed=88.78 sec\n",
            "epoch 12 (227/272) | step 3220 | avg_nll=14.64 avg_ppl=7.45 speed=9915.32 words/sec time_elapsed=89.02 sec\n",
            "epoch 12 (237/272) | step 3230 | avg_nll=15.28 avg_ppl=8.00 speed=10336.16 words/sec time_elapsed=89.24 sec\n",
            "epoch 12 (247/272) | step 3240 | avg_nll=15.35 avg_ppl=8.19 speed=10345.74 words/sec time_elapsed=89.47 sec\n",
            "epoch 12 (257/272) | step 3250 | avg_nll=15.39 avg_ppl=7.95 speed=9856.81 words/sec time_elapsed=89.71 sec\n",
            "epoch 12 (267/272) | step 3260 | avg_nll=15.20 avg_ppl=8.17 speed=10206.75 words/sec time_elapsed=89.94 sec\n",
            "epoch 13 (5/272) | step 3270 | avg_nll=13.53 avg_ppl=6.65 speed=10008.67 words/sec time_elapsed=90.17 sec\n",
            "epoch 13 (15/272) | step 3280 | avg_nll=13.30 avg_ppl=6.28 speed=10285.85 words/sec time_elapsed=90.39 sec\n",
            "epoch 13 (25/272) | step 3290 | avg_nll=14.17 avg_ppl=7.25 speed=9929.97 words/sec time_elapsed=90.62 sec\n",
            "epoch 13 (35/272) | step 3300 | avg_nll=13.38 avg_ppl=6.35 speed=9589.02 words/sec time_elapsed=90.86 sec\n",
            "Begin validation ...\n",
            "validation: step 3300 | dev_ppl=9.490224838256836\n",
            "epoch 13 (45/272) | step 3310 | avg_nll=13.95 avg_ppl=6.88 speed=6410.49 words/sec time_elapsed=91.22 sec\n",
            "epoch 13 (55/272) | step 3320 | avg_nll=14.02 avg_ppl=7.02 speed=10047.52 words/sec time_elapsed=91.45 sec\n",
            "epoch 13 (65/272) | step 3330 | avg_nll=13.72 avg_ppl=6.59 speed=9703.19 words/sec time_elapsed=91.69 sec\n",
            "epoch 13 (75/272) | step 3340 | avg_nll=14.46 avg_ppl=7.11 speed=10449.50 words/sec time_elapsed=91.92 sec\n",
            "epoch 13 (85/272) | step 3350 | avg_nll=13.59 avg_ppl=6.71 speed=9813.92 words/sec time_elapsed=92.15 sec\n",
            "epoch 13 (95/272) | step 3360 | avg_nll=14.68 avg_ppl=7.53 speed=10460.68 words/sec time_elapsed=92.37 sec\n",
            "epoch 13 (105/272) | step 3370 | avg_nll=14.11 avg_ppl=6.97 speed=10259.41 words/sec time_elapsed=92.60 sec\n",
            "epoch 13 (115/272) | step 3380 | avg_nll=13.14 avg_ppl=6.11 speed=6760.98 words/sec time_elapsed=92.95 sec\n",
            "epoch 13 (125/272) | step 3390 | avg_nll=13.70 avg_ppl=6.56 speed=7218.37 words/sec time_elapsed=93.27 sec\n",
            "epoch 13 (135/272) | step 3400 | avg_nll=13.55 avg_ppl=6.41 speed=7577.62 words/sec time_elapsed=93.58 sec\n",
            "Begin validation ...\n",
            "validation: step 3400 | dev_ppl=9.572500228881836\n",
            "epoch 13 (145/272) | step 3410 | avg_nll=15.24 avg_ppl=7.77 speed=4239.42 words/sec time_elapsed=94.14 sec\n",
            "epoch 13 (155/272) | step 3420 | avg_nll=14.27 avg_ppl=7.36 speed=6407.45 words/sec time_elapsed=94.50 sec\n",
            "epoch 13 (165/272) | step 3430 | avg_nll=14.51 avg_ppl=7.25 speed=6145.95 words/sec time_elapsed=94.88 sec\n",
            "epoch 13 (175/272) | step 3440 | avg_nll=12.55 avg_ppl=5.80 speed=6306.32 words/sec time_elapsed=95.24 sec\n",
            "epoch 13 (185/272) | step 3450 | avg_nll=13.32 avg_ppl=6.29 speed=7876.15 words/sec time_elapsed=95.54 sec\n",
            "epoch 13 (195/272) | step 3460 | avg_nll=13.74 avg_ppl=6.95 speed=8931.54 words/sec time_elapsed=95.79 sec\n",
            "epoch 13 (205/272) | step 3470 | avg_nll=13.62 avg_ppl=6.62 speed=9958.30 words/sec time_elapsed=96.02 sec\n",
            "epoch 13 (215/272) | step 3480 | avg_nll=13.08 avg_ppl=6.13 speed=10160.38 words/sec time_elapsed=96.25 sec\n",
            "epoch 13 (225/272) | step 3490 | avg_nll=14.93 avg_ppl=7.84 speed=10059.01 words/sec time_elapsed=96.48 sec\n",
            "epoch 13 (235/272) | step 3500 | avg_nll=13.77 avg_ppl=6.73 speed=10183.07 words/sec time_elapsed=96.71 sec\n",
            "Begin validation ...\n",
            "validation: step 3500 | dev_ppl=9.394414901733398\n",
            "epoch 13 (245/272) | step 3510 | avg_nll=14.40 avg_ppl=7.23 speed=6100.34 words/sec time_elapsed=97.09 sec\n",
            "epoch 13 (255/272) | step 3520 | avg_nll=13.14 avg_ppl=6.31 speed=10077.62 words/sec time_elapsed=97.32 sec\n",
            "epoch 13 (265/272) | step 3530 | avg_nll=13.75 avg_ppl=6.54 speed=10449.77 words/sec time_elapsed=97.54 sec\n",
            "epoch 14 (3/272) | step 3540 | avg_nll=14.44 avg_ppl=7.30 speed=10153.07 words/sec time_elapsed=97.77 sec\n",
            "epoch 14 (13/272) | step 3550 | avg_nll=12.21 avg_ppl=5.63 speed=9557.74 words/sec time_elapsed=98.01 sec\n",
            "epoch 14 (23/272) | step 3560 | avg_nll=14.12 avg_ppl=6.73 speed=10312.08 words/sec time_elapsed=98.24 sec\n",
            "epoch 14 (33/272) | step 3570 | avg_nll=12.73 avg_ppl=5.82 speed=9980.98 words/sec time_elapsed=98.47 sec\n",
            "epoch 14 (43/272) | step 3580 | avg_nll=13.04 avg_ppl=6.19 speed=9826.74 words/sec time_elapsed=98.70 sec\n",
            "epoch 14 (53/272) | step 3590 | avg_nll=12.69 avg_ppl=5.72 speed=9876.55 words/sec time_elapsed=98.94 sec\n",
            "epoch 14 (63/272) | step 3600 | avg_nll=14.65 avg_ppl=7.40 speed=10183.36 words/sec time_elapsed=99.17 sec\n",
            "Begin validation ...\n",
            "validation: step 3600 | dev_ppl=9.033883094787598\n",
            "epoch 14 step 3600: save currently the best model to 'model.pt'\n",
            "epoch 14 (73/272) | step 3610 | avg_nll=13.94 avg_ppl=6.80 speed=5884.11 words/sec time_elapsed=99.56 sec\n",
            "epoch 14 (83/272) | step 3620 | avg_nll=12.93 avg_ppl=6.04 speed=9878.56 words/sec time_elapsed=99.80 sec\n",
            "epoch 14 (93/272) | step 3630 | avg_nll=13.42 avg_ppl=6.38 speed=9666.86 words/sec time_elapsed=100.04 sec\n",
            "epoch 14 (103/272) | step 3640 | avg_nll=13.35 avg_ppl=6.34 speed=10023.48 words/sec time_elapsed=100.27 sec\n",
            "epoch 14 (113/272) | step 3650 | avg_nll=13.52 avg_ppl=6.45 speed=10440.83 words/sec time_elapsed=100.49 sec\n",
            "epoch 14 (123/272) | step 3660 | avg_nll=12.95 avg_ppl=6.12 speed=9779.00 words/sec time_elapsed=100.72 sec\n",
            "epoch 14 (133/272) | step 3670 | avg_nll=13.42 avg_ppl=6.16 speed=9782.14 words/sec time_elapsed=100.97 sec\n",
            "epoch 14 (143/272) | step 3680 | avg_nll=13.74 avg_ppl=6.51 speed=10061.27 words/sec time_elapsed=101.20 sec\n",
            "epoch 14 (153/272) | step 3690 | avg_nll=12.49 avg_ppl=5.82 speed=9796.25 words/sec time_elapsed=101.43 sec\n",
            "epoch 14 (163/272) | step 3700 | avg_nll=12.54 avg_ppl=5.75 speed=10012.18 words/sec time_elapsed=101.66 sec\n",
            "Begin validation ...\n",
            "validation: step 3700 | dev_ppl=8.888405799865723\n",
            "epoch 14 step 3700: save currently the best model to 'model.pt'\n",
            "epoch 14 (173/272) | step 3710 | avg_nll=12.99 avg_ppl=6.10 speed=5526.76 words/sec time_elapsed=102.08 sec\n",
            "epoch 14 (183/272) | step 3720 | avg_nll=13.56 avg_ppl=6.34 speed=10704.55 words/sec time_elapsed=102.30 sec\n",
            "epoch 14 (193/272) | step 3730 | avg_nll=13.61 avg_ppl=6.44 speed=10535.68 words/sec time_elapsed=102.52 sec\n",
            "epoch 14 (203/272) | step 3740 | avg_nll=12.93 avg_ppl=6.18 speed=8959.36 words/sec time_elapsed=102.77 sec\n",
            "epoch 14 (213/272) | step 3750 | avg_nll=13.92 avg_ppl=6.76 speed=9750.66 words/sec time_elapsed=103.01 sec\n",
            "epoch 14 (223/272) | step 3760 | avg_nll=13.68 avg_ppl=6.59 speed=10055.34 words/sec time_elapsed=103.24 sec\n",
            "epoch 14 (233/272) | step 3770 | avg_nll=12.76 avg_ppl=5.85 speed=10305.51 words/sec time_elapsed=103.47 sec\n",
            "epoch 14 (243/272) | step 3780 | avg_nll=13.08 avg_ppl=6.12 speed=10329.83 words/sec time_elapsed=103.69 sec\n",
            "epoch 14 (253/272) | step 3790 | avg_nll=13.99 avg_ppl=6.74 speed=10261.22 words/sec time_elapsed=103.92 sec\n",
            "epoch 14 (263/272) | step 3800 | avg_nll=13.11 avg_ppl=6.05 speed=9450.61 words/sec time_elapsed=104.16 sec\n",
            "Begin validation ...\n",
            "validation: step 3800 | dev_ppl=8.827735900878906\n",
            "epoch 14 step 3800: save currently the best model to 'model.pt'\n",
            "epoch 15 (1/272) | step 3810 | avg_nll=12.72 avg_ppl=5.90 speed=5813.05 words/sec time_elapsed=104.56 sec\n",
            "epoch 15 (11/272) | step 3820 | avg_nll=13.33 avg_ppl=6.28 speed=10240.97 words/sec time_elapsed=104.79 sec\n",
            "epoch 15 (21/272) | step 3830 | avg_nll=12.48 avg_ppl=5.63 speed=9700.94 words/sec time_elapsed=105.02 sec\n",
            "epoch 15 (31/272) | step 3840 | avg_nll=11.86 avg_ppl=5.23 speed=10122.98 words/sec time_elapsed=105.25 sec\n",
            "epoch 15 (41/272) | step 3850 | avg_nll=12.69 avg_ppl=5.55 speed=7380.15 words/sec time_elapsed=105.57 sec\n",
            "epoch 15 (51/272) | step 3860 | avg_nll=12.37 avg_ppl=5.51 speed=6314.48 words/sec time_elapsed=105.94 sec\n",
            "epoch 15 (61/272) | step 3870 | avg_nll=13.58 avg_ppl=6.55 speed=6642.56 words/sec time_elapsed=106.29 sec\n",
            "epoch 15 (71/272) | step 3880 | avg_nll=12.22 avg_ppl=5.45 speed=7568.66 words/sec time_elapsed=106.59 sec\n",
            "epoch 15 (81/272) | step 3890 | avg_nll=12.67 avg_ppl=5.77 speed=6556.60 words/sec time_elapsed=106.95 sec\n",
            "epoch 15 (91/272) | step 3900 | avg_nll=12.66 avg_ppl=5.76 speed=6008.06 words/sec time_elapsed=107.33 sec\n",
            "Begin validation ...\n",
            "validation: step 3900 | dev_ppl=8.822685241699219\n",
            "epoch 15 step 3900: save currently the best model to 'model.pt'\n",
            "epoch 15 (101/272) | step 3910 | avg_nll=12.70 avg_ppl=5.80 speed=3692.51 words/sec time_elapsed=107.96 sec\n",
            "epoch 15 (111/272) | step 3920 | avg_nll=12.57 avg_ppl=5.85 speed=9124.49 words/sec time_elapsed=108.21 sec\n",
            "epoch 15 (121/272) | step 3930 | avg_nll=12.03 avg_ppl=5.32 speed=10225.71 words/sec time_elapsed=108.44 sec\n",
            "epoch 15 (131/272) | step 3940 | avg_nll=13.56 avg_ppl=6.10 speed=10455.04 words/sec time_elapsed=108.67 sec\n",
            "epoch 15 (141/272) | step 3950 | avg_nll=12.44 avg_ppl=5.52 speed=9885.44 words/sec time_elapsed=108.90 sec\n",
            "epoch 15 (151/272) | step 3960 | avg_nll=12.44 avg_ppl=5.73 speed=9331.58 words/sec time_elapsed=109.15 sec\n",
            "epoch 15 (161/272) | step 3970 | avg_nll=13.10 avg_ppl=6.19 speed=10083.69 words/sec time_elapsed=109.37 sec\n",
            "epoch 15 (171/272) | step 3980 | avg_nll=13.05 avg_ppl=6.25 speed=10084.15 words/sec time_elapsed=109.60 sec\n",
            "epoch 15 (181/272) | step 3990 | avg_nll=12.44 avg_ppl=5.54 speed=9822.67 words/sec time_elapsed=109.84 sec\n",
            "epoch 15 (191/272) | step 4000 | avg_nll=12.53 avg_ppl=5.70 speed=9395.01 words/sec time_elapsed=110.08 sec\n",
            "Begin validation ...\n",
            "validation: step 4000 | dev_ppl=8.510330200195312\n",
            "epoch 15 step 4000: save currently the best model to 'model.pt'\n",
            "epoch 15 (201/272) | step 4010 | avg_nll=13.05 avg_ppl=6.04 speed=5470.05 words/sec time_elapsed=110.51 sec\n",
            "epoch 15 (211/272) | step 4020 | avg_nll=12.87 avg_ppl=5.79 speed=8992.04 words/sec time_elapsed=110.77 sec\n",
            "epoch 15 (221/272) | step 4030 | avg_nll=13.28 avg_ppl=6.20 speed=9858.48 words/sec time_elapsed=111.00 sec\n",
            "epoch 15 (231/272) | step 4040 | avg_nll=12.74 avg_ppl=5.83 speed=9656.13 words/sec time_elapsed=111.24 sec\n",
            "epoch 15 (241/272) | step 4050 | avg_nll=13.70 avg_ppl=6.44 speed=10604.22 words/sec time_elapsed=111.47 sec\n",
            "epoch 15 (251/272) | step 4060 | avg_nll=12.62 avg_ppl=5.82 speed=9962.42 words/sec time_elapsed=111.70 sec\n",
            "epoch 15 (261/272) | step 4070 | avg_nll=12.53 avg_ppl=5.67 speed=9831.58 words/sec time_elapsed=111.93 sec\n",
            "epoch 15 (271/272) | step 4080 | avg_nll=12.68 avg_ppl=5.74 speed=9391.27 words/sec time_elapsed=112.18 sec\n",
            "Reached maximum number of epochs\n"
          ]
        }
      ],
      "source": [
        "# Set a random seed, so you obtain the same output model if you run this cell again.\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "model = EncoderDecoderModel(\n",
        "    source_vocab_size=source_tokenizer.vocab_size,\n",
        "    target_vocab_size=target_tokenizer.vocab_size,\n",
        "    hidden_size=32,\n",
        "    intermediate_size=32 * 4,\n",
        "    num_attention_heads=4,\n",
        "    num_encoder_layers=3,\n",
        "    num_decoder_layers=3,\n",
        "    max_sequence_length=32,\n",
        "    hidden_dropout_prob=0.1,\n",
        "    )\n",
        "\n",
        "print(\"Model architecture:\", model)\n",
        "print(\"Total number of trainable model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"We are in datasets train\")\n",
        "print(tokenized_datasets[\"train\"])\n",
        "train(model, tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"],\n",
        "      max_epoch=15, model_path=\"model.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhk9wiHzpyuF"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "We have trained a seq2seq model for the NMT task. Now let's evaluate the model on the test set by generating translations with beam search and comparing them to the gold translations using the BLEU score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqEeZlyeuzG2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def beam_search(model: EncoderDecoderModel,\n",
        "                encoder_input_ids: torch.LongTensor,\n",
        "                beam_width: int = 5,\n",
        "                max_len: int = 32) -> Tuple[torch.LongTensor, float]:\n",
        "    \"\"\"Run beam search on the encoder-decoder model for a single source sequence.\n",
        "\n",
        "    Args:\n",
        "        model: The encoder-decoder model.\n",
        "        encoder_input_ids: The input sequence. Tensor of shape [encoder_sequence_length].\n",
        "        beam_width: Number of generations to expand at each time step.\n",
        "        max_len: Stop generation when reaching this length for the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        A tuple (generation, score) where generation is the generated target sequence and\n",
        "            a tensor of shape [target_sequence_length] and score is the corresponding\n",
        "            log-probability of this generation.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    encoder_input_ids = encoder_input_ids.unsqueeze(0) # Add the batch dimension\n",
        "    encoder_padding_mask = torch.zeros_like(encoder_input_ids, dtype=torch.bool) # No padding\n",
        "    encoder_outputs = model.forward_encoder(encoder_input_ids, encoder_padding_mask)\n",
        "\n",
        "    generations = [torch.tensor([target_tokenizer.bos_token_id], device=encoder_input_ids.device)]\n",
        "    scores = [0.0]\n",
        "\n",
        "    best_generation = None\n",
        "    best_score = float('-inf')\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_generations = []\n",
        "        new_scores = []\n",
        "        for score, generation in zip(scores, generations):\n",
        "            generation = generation.unsqueeze(0) # Add the batch dimension\n",
        "            padding_mask = torch.zeros_like(generation, dtype=torch.bool) # No padding\n",
        "            decoder_output = model.forward_decoder(generation, padding_mask, encoder_outputs, encoder_padding_mask)\n",
        "            last_log_probs = decoder_output[0, -1, :].log_softmax(dim=-1)\n",
        "            top_log_probs, top_indices = last_log_probs.topk(beam_width, dim=-1)\n",
        "\n",
        "            new_generations.append(torch.cat([generation.expand(beam_width, -1), top_indices[:,None]], dim=1))\n",
        "            new_scores.append(score + top_log_probs)\n",
        "\n",
        "        new_generations = torch.cat(new_generations, dim=0)\n",
        "        new_scores = torch.cat(new_scores, dim=0)\n",
        "\n",
        "        ends_with_eos = target_tokenizer.eos_token_id == new_generations[:,-1]\n",
        "\n",
        "        if ends_with_eos.any():\n",
        "            new_completed_generations = new_generations[ends_with_eos]\n",
        "            new_completed_scores = new_scores[ends_with_eos]\n",
        "\n",
        "            if new_completed_scores.max() > best_score:\n",
        "                best_score = new_completed_scores.max()\n",
        "                best_generation = new_completed_generations[new_completed_scores.argmax()]\n",
        "\n",
        "        if best_score >= new_scores.max():\n",
        "            break\n",
        "\n",
        "        scores, indices = torch.topk(new_scores, beam_width, dim=-1)\n",
        "        generations = new_generations[indices]\n",
        "\n",
        "    if best_generation is None:\n",
        "        best_generation = generations[0]\n",
        "        best_score = scores[0]\n",
        "\n",
        "    return best_generation, best_score.cpu().item()\n",
        "\n",
        "\n",
        "def run_generation(model, test_dataset, beam_size=5, max_decoding_time_step=32):\n",
        "    \"\"\"Run beam search decoding on the test set, compute BLEU and return reference and candidate target sentences.\n",
        "    \"\"\"\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Use device: %s' % device)\n",
        "\n",
        "    input_sentences = []\n",
        "    reference_sentences = []\n",
        "    candidate_sentences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for example in tqdm(test_dataset):\n",
        "            encoder_input_ids = torch.tensor(example[\"encoder_input_ids\"], device=device)\n",
        "\n",
        "            generation, _ = beam_search(model, encoder_input_ids, beam_size, max_decoding_time_step)\n",
        "\n",
        "            # Decode given source sequence and generated target sequence and avoid special tokens\n",
        "\n",
        "            input_text = \"\".join(source_tokenizer.decode(token).replace(\"▁\", \" \") for token in example[\"encoder_input_ids\"][1:-1])\n",
        "            reference_text = \"\".join(target_tokenizer.decode(token).replace(\"▁\", \" \") for token in example[\"decoder_input_ids\"][1:-1])\n",
        "            candidate_text = \"\".join(target_tokenizer.decode(token).replace(\"▁\", \" \") for token in generation[1:-1].cpu())\n",
        "\n",
        "            reference_sentences.append(reference_text)\n",
        "            candidate_sentences.append(candidate_text)\n",
        "            input_sentences.append(input_text)\n",
        "\n",
        "\n",
        "    bleu_score = corpus_bleu([[ref] for ref in reference_sentences],\n",
        "                             [candidate for candidate in candidate_sentences])\n",
        "\n",
        "    return bleu_score, input_sentences, reference_sentences, candidate_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRjz11ntwgkK",
        "outputId": "5460d379-e17c-4a81-e81d-bb0814462256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 486/486 [00:58<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Corpus BLEU: 48.42080635089672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Restore the best validation checkpoint\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "\n",
        "bleu_score, inputs, references, candidates = run_generation(model, tokenized_datasets[\"test\"])\n",
        "print('\\n\\nCorpus BLEU: {}'.format(bleu_score * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOLmb9eh6kua"
      },
      "source": [
        "Let's look at some examples. What do you think of the quality of the translations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5e1cDYe6t0B",
        "outputId": "248c22de-a272-419e-dc92-d07f847c0f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Sample 10 =====\n",
            "Input:  vous me mettez mal a l aise .\n",
            "Gold:  you re embarrassing me .\n",
            "Pred:  i m waiting for it of it .\n",
            "===== Sample 11 =====\n",
            "Input:  c est toi le professeur .\n",
            "Gold:  you re the teacher .\n",
            "Pred:  you re the teacher .\n",
            "===== Sample 12 =====\n",
            "Input:  elle sourit avec bonheur .\n",
            "Gold:  she smiled happily .\n",
            "Pred:  she is good at to him .\n",
            "===== Sample 13 =====\n",
            "Input:  je ne suis pas devin .\n",
            "Gold:  i m not a psychic .\n",
            "Pred:  i m not taking .\n",
            "===== Sample 14 =====\n",
            "Input:  vous allez perdre .\n",
            "Gold:  you re going to lose .\n",
            "Pred:  you re going to with\n",
            "===== Sample 15 =====\n",
            "Input:  vous me touchez .\n",
            "Gold:  you re touching me .\n",
            "Pred:  you re bored .\n",
            "===== Sample 16 =====\n",
            "Input:  je pars aujourd hui .\n",
            "Gold:  i m leaving today .\n",
            "Pred:  i m ready .\n",
            "===== Sample 17 =====\n",
            "Input:  je ne suis pas une sainte .\n",
            "Gold:  i m no saint .\n",
            "Pred:  i m not a now .\n",
            "===== Sample 18 =====\n",
            "Input:  je suis puissant .\n",
            "Gold:  i m powerful .\n",
            "Pred:  i m early .\n",
            "===== Sample 19 =====\n",
            "Input:  vous n etes qu un lache .\n",
            "Gold:  you re nothing but a coward .\n",
            "Pred:  you re just for a invited it .\n",
            "===== Sample 20 =====\n",
            "Input:  je suis fier de vous tous .\n",
            "Gold:  i m proud of you all .\n",
            "Pred:  i m proud of my you .\n",
            "===== Sample 21 =====\n",
            "Input:  vous etes un merveilleux ami .\n",
            "Gold:  you re a wonderful friend .\n",
            "Pred:  you re a friend friend .\n",
            "===== Sample 22 =====\n",
            "Input:  il a l habitude des ordinateurs .\n",
            "Gold:  he is familiar with computers .\n",
            "Pred:  he is very good ating .\n",
            "===== Sample 23 =====\n",
            "Input:  vous etes plus grands que moi .\n",
            "Gold:  you re taller than i am .\n",
            "Pred:  you re taller than me .\n",
            "===== Sample 24 =====\n",
            "Input:  vous avez peur pas vrai ?\n",
            "Gold:  you re afraid aren t you ?\n",
            "Pred:  you re still aren t you ?\n",
            "===== Sample 25 =====\n",
            "Input:  je ne fais pas partie de leur bande .\n",
            "Gold:  i m not one of them .\n",
            "Pred:  i m not an\n",
            "===== Sample 26 =====\n",
            "Input:  vous etes tres comprehensives .\n",
            "Gold:  you re very understanding .\n",
            "Pred:  you re very brave .\n",
            "===== Sample 27 =====\n",
            "Input:  vous vous approchez .\n",
            "Gold:  you re getting closer .\n",
            "Pred:  you re big .\n",
            "===== Sample 28 =====\n",
            "Input:  vous dites toujours ca .\n",
            "Gold:  you re always saying that .\n",
            "Pred:  you re always disturbed than me .\n",
            "===== Sample 29 =====\n",
            "Input:  je conte une histoire .\n",
            "Gold:  i am telling a story .\n",
            "Pred:  i m she .\n",
            "===== Sample 30 =====\n",
            "Input:  il est photographe professionnel .\n",
            "Gold:  he s a professional photographer .\n",
            "Pred:  he is a a now .\n",
            "===== Sample 31 =====\n",
            "Input:  vous etes incroyables .\n",
            "Gold:  you re incredible .\n",
            "Pred:  you re beautiful .\n",
            "===== Sample 32 =====\n",
            "Input:  je suis desole .\n",
            "Gold:  i m sorry .\n",
            "Pred:  i m sorry .\n",
            "===== Sample 33 =====\n",
            "Input:  elle lui sourit avec gene .\n",
            "Gold:  she smiled at him uneasily .\n",
            "Pred:  she is him .\n",
            "===== Sample 34 =====\n",
            "Input:  nous sommes freres .\n",
            "Gold:  we re brothers .\n",
            "Pred:  we reation .\n",
            "===== Sample 35 =====\n",
            "Input:  vous n etes pas fatiguees si ?\n",
            "Gold:  you re not tired are you ?\n",
            "Pred:  you re not tired are you ?\n",
            "===== Sample 36 =====\n",
            "Input:  nous sommes debout .\n",
            "Gold:  we re standing .\n",
            "Pred:  we re english .\n",
            "===== Sample 37 =====\n",
            "Input:  je casse mes nouvelles chaussures .\n",
            "Gold:  i m breaking in my new shoes .\n",
            "Pred:  i m working for friends .\n",
            "===== Sample 38 =====\n",
            "Input:  je crains de vous avoir offense .\n",
            "Gold:  i m afraid i ve offended you .\n",
            "Pred:  i m afraid i is you .\n",
            "===== Sample 39 =====\n",
            "Input:  vous conduisez comme un tare !\n",
            "Gold:  you re driving like a maniac !\n",
            "Pred:  you re decisions .\n",
            "===== Sample 40 =====\n",
            "Input:  je suis heureux ici .\n",
            "Gold:  i m happy here .\n",
            "Pred:  i m happy here .\n",
            "===== Sample 41 =====\n",
            "Input:  il est en bonne condition physique .\n",
            "Gold:  he is in good physical condition .\n",
            "Pred:  he is a good good at brother .\n",
            "===== Sample 42 =====\n",
            "Input:  elles le font comme il faut .\n",
            "Gold:  they re doing it right .\n",
            "Pred:  they are right friend .\n",
            "===== Sample 43 =====\n",
            "Input:  nous y sommes actuellement .\n",
            "Gold:  we re here now .\n",
            "Pred:  we re tom .\n",
            "===== Sample 44 =====\n",
            "Input:  je vais etre votre institutrice .\n",
            "Gold:  i m going to be your teacher .\n",
            "Pred:  i m going to your your shy .\n",
            "===== Sample 45 =====\n",
            "Input:  elle adore chanter de vieilles chansons .\n",
            "Gold:  she is fond of singing old songs .\n",
            "Pred:  she is a to is .\n",
            "===== Sample 46 =====\n",
            "Input:  nous sommes en train de bouger .\n",
            "Gold:  we re moving .\n",
            "Pred:  we re sick .\n",
            "===== Sample 47 =====\n",
            "Input:  on vous demande au telephone .\n",
            "Gold:  you re wanted on the telephone .\n",
            "Pred:  we re not married .\n",
            "===== Sample 48 =====\n",
            "Input:  vous etes nouvelles ici n est ce pas ?\n",
            "Gold:  you re new here aren t you ?\n",
            "Pred:  you re here aren t you ?\n",
            "===== Sample 49 =====\n",
            "Input:  tu es trop confiante .\n",
            "Gold:  you re too trusting .\n",
            "Pred:  you re too him .\n",
            "===== Sample 50 =====\n",
            "Input:  nous en avons completement termine ici .\n",
            "Gold:  we re all done here .\n",
            "Pred:  we re finished here .\n",
            "===== Sample 51 =====\n",
            "Input:  tu es fort effronte .\n",
            "Gold:  you re very forward .\n",
            "Pred:  you re very forward .\n",
            "===== Sample 52 =====\n",
            "Input:  je suis sure qu il reussira .\n",
            "Gold:  i am sure of his success .\n",
            "Pred:  i m sure it .\n",
            "===== Sample 53 =====\n",
            "Input:  je ne suis toujours pas sure .\n",
            "Gold:  i m still not sure .\n",
            "Pred:  i m still always happy .\n",
            "===== Sample 54 =====\n",
            "Input:  je ne suis pas si malin .\n",
            "Gold:  i m not all that smart .\n",
            "Pred:  i m not so you .\n",
            "===== Sample 55 =====\n",
            "Input:  j ai honte de moi meme .\n",
            "Gold:  i m ashamed of myself .\n",
            "Pred:  i am ashamed of words .\n",
            "===== Sample 56 =====\n",
            "Input:  tu es trop vieux pour moi .\n",
            "Gold:  you re too old for me .\n",
            "Pred:  you re too old for me .\n",
            "===== Sample 57 =====\n",
            "Input:  vous etes tres gentils .\n",
            "Gold:  you re very nice .\n",
            "Pred:  you re very upset .\n",
            "===== Sample 58 =====\n",
            "Input:  ils sont acteurs .\n",
            "Gold:  they are actors .\n",
            "Pred:  they re crazy .\n",
            "===== Sample 59 =====\n",
            "Input:  je crains que nous ne puissions vous aider .\n",
            "Gold:  i m afraid we can t help you .\n",
            "Pred:  i m afraid getting getting it .\n",
            "===== Sample 60 =====\n",
            "Input:  vous etes un amour !\n",
            "Gold:  you re a doll !\n",
            "Pred:  you re a liar !\n",
            "===== Sample 61 =====\n",
            "Input:  tu es oublieuse .\n",
            "Gold:  you re forgetful .\n",
            "Pred:  you re forgetful .\n",
            "===== Sample 62 =====\n",
            "Input:  vous n etes pas de mes amis .\n",
            "Gold:  you re no friend of mine .\n",
            "Pred:  you re not tired .\n",
            "===== Sample 63 =====\n",
            "Input:  nous sommes certains .\n",
            "Gold:  we re certain .\n",
            "Pred:  we re having .\n",
            "===== Sample 64 =====\n",
            "Input:  t es une drole de fille .\n",
            "Gold:  you re a funny girl .\n",
            "Pred:  you re a .\n",
            "===== Sample 65 =====\n",
            "Input:  vous etes tres belle .\n",
            "Gold:  you are very beautiful .\n",
            "Pred:  you re very beautiful .\n",
            "===== Sample 66 =====\n",
            "Input:  je suis content que ca vous rende heureuse .\n",
            "Gold:  i m glad that makes you happy .\n",
            "Pred:  i m glad that makes you happy .\n",
            "===== Sample 67 =====\n",
            "Input:  j en ai marre de toi .\n",
            "Gold:  i m sick of you .\n",
            "Pred:  i m sick with you .\n",
            "===== Sample 68 =====\n",
            "Input:  vous etes toujours vivants .\n",
            "Gold:  you re still alive .\n",
            "Pred:  you re still beautiful .\n",
            "===== Sample 69 =====\n",
            "Input:  elles sont mignonnes .\n",
            "Gold:  they re cute .\n",
            "Pred:  they re happy .\n"
          ]
        }
      ],
      "source": [
        "# Feel free to change the range to look at more samples!\n",
        "for k in range(10, 70):\n",
        "  print(f\"===== Sample {k} =====\")\n",
        "  print(f\"Input: {inputs[k]}\")\n",
        "  print(f\"Gold: {references[k]}\")\n",
        "  print(f\"Pred: {candidates[k]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ae846721324468eb29cf8e5154ef661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a1a4551f0f94a01bcfce63a61d70152",
              "IPY_MODEL_cec3fe713de34cf08f3f02bc784fccc3",
              "IPY_MODEL_20237bfdb8b44f308c3a36b9e694dd52"
            ],
            "layout": "IPY_MODEL_e067e961c0f44b5aa34cd7708080bbf5"
          }
        },
        "3a1a4551f0f94a01bcfce63a61d70152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755a7f249f2c48bf9c1a2d0606f7ce01",
            "placeholder": "​",
            "style": "IPY_MODEL_1da76628f79e4805bf6f4a4c95322510",
            "value": "Map:  98%"
          }
        },
        "cec3fe713de34cf08f3f02bc784fccc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eefe37f41484e9ab2930485fe142601",
            "max": 8701,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66926707f2534cb98a9f1203d82cf00b",
            "value": 8701
          }
        },
        "20237bfdb8b44f308c3a36b9e694dd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e77654103dc4fe9b9a12a8ea16e166e",
            "placeholder": "​",
            "style": "IPY_MODEL_70f8f8f39dff496589367bb5ce6c5a35",
            "value": " 8503/8701 [00:05&lt;00:00, 2669.12 examples/s]"
          }
        },
        "e067e961c0f44b5aa34cd7708080bbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "755a7f249f2c48bf9c1a2d0606f7ce01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da76628f79e4805bf6f4a4c95322510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eefe37f41484e9ab2930485fe142601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66926707f2534cb98a9f1203d82cf00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e77654103dc4fe9b9a12a8ea16e166e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f8f8f39dff496589367bb5ce6c5a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0222d46c7b7542e2b0864b99bfbde062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f0e96193db94721aa1e628826877dbf",
              "IPY_MODEL_ee8559723f6a451196fc49f9780eb7a8",
              "IPY_MODEL_bd3da4b876724cc6b38a61e5074cedc0"
            ],
            "layout": "IPY_MODEL_81a093b65ac14ce098b064fa31b76aa9"
          }
        },
        "5f0e96193db94721aa1e628826877dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2b4dbf424c4ba9b3073a2d2be907a0",
            "placeholder": "​",
            "style": "IPY_MODEL_40162021b70b45aa864078ff49d2d0bb",
            "value": "Map: 100%"
          }
        },
        "ee8559723f6a451196fc49f9780eb7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7249d0ad79143cfa37040e3cc4fec55",
            "max": 485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75737cd71c2644a982f8dcc53228a9c4",
            "value": 485
          }
        },
        "bd3da4b876724cc6b38a61e5074cedc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97bf8967c3c74113a2a83dd350e7860b",
            "placeholder": "​",
            "style": "IPY_MODEL_eb647d942b04475e97c9bd80b0d11ff3",
            "value": " 485/485 [00:00&lt;00:00, 2146.81 examples/s]"
          }
        },
        "81a093b65ac14ce098b064fa31b76aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "de2b4dbf424c4ba9b3073a2d2be907a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40162021b70b45aa864078ff49d2d0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7249d0ad79143cfa37040e3cc4fec55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75737cd71c2644a982f8dcc53228a9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97bf8967c3c74113a2a83dd350e7860b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb647d942b04475e97c9bd80b0d11ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e96ce9e1257e4e00943b2f8a207c729c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_465bc1cd7f944410aea3bc39206dd00a",
              "IPY_MODEL_f91b3fdc63d949609448f6b7e596a061",
              "IPY_MODEL_49229dff63fd4f19820a6e4bc85e75ba"
            ],
            "layout": "IPY_MODEL_f1a607275fc44d0095cbca082132a9a9"
          }
        },
        "465bc1cd7f944410aea3bc39206dd00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e5132579e0483a9c480b24794ceea5",
            "placeholder": "​",
            "style": "IPY_MODEL_b1845194a1ad4ff28053ab5b7adea400",
            "value": "Map: 100%"
          }
        },
        "f91b3fdc63d949609448f6b7e596a061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8fa8069369d41b8932d9d9a92541041",
            "max": 486,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_023b8a95d97b45e2be78d8330671d2fc",
            "value": 486
          }
        },
        "49229dff63fd4f19820a6e4bc85e75ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aca2d9b84764f2c9fd1a46531ee8d69",
            "placeholder": "​",
            "style": "IPY_MODEL_9af3b1377f9442608a493e30b25b8162",
            "value": " 486/486 [00:00&lt;00:00, 2014.80 examples/s]"
          }
        },
        "f1a607275fc44d0095cbca082132a9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "60e5132579e0483a9c480b24794ceea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1845194a1ad4ff28053ab5b7adea400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8fa8069369d41b8932d9d9a92541041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023b8a95d97b45e2be78d8330671d2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aca2d9b84764f2c9fd1a46531ee8d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af3b1377f9442608a493e30b25b8162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}